CONFIG
â”œâ”€â”€ train
â”‚   â””â”€â”€ seed: 2222                                                              
â”‚       name: null                                                              
â”‚       interval: step                                                          
â”‚       monitor: val/accuracy                                                   
â”‚       mode: max                                                               
â”‚       ema: 0.0                                                                
â”‚       test: false                                                             
â”‚       debug: false                                                            
â”‚       ignore_warnings: false                                                  
â”‚       state:                                                                  
â”‚         mode: null                                                            
â”‚         n_context: 0                                                          
â”‚         n_context_eval: 0                                                     
â”‚       ckpt: null                                                              
â”‚       disable_dataset: false                                                  
â”‚       validate_at_start: false                                                
â”‚       pretrained_model_path: null                                             
â”‚       pretrained_model_strict_load: true                                      
â”‚       pretrained_model_state_hook:                                            
â”‚         _name_: null                                                          
â”‚       post_init_hook:                                                         
â”‚         _name_: null                                                          
â”‚       layer_decay:                                                            
â”‚         _name_: null                                                          
â”‚         decay: 0.7                                                            
â”‚                                                                               
â”œâ”€â”€ tolerance
â”‚   â””â”€â”€ logdir: ./resume                                                        
â”‚       id: null                                                                
â”‚                                                                               
â”œâ”€â”€ wandb
â”‚   â””â”€â”€ project: TNLM                                                           
â”‚       group: ''                                                               
â”‚       job_type: training                                                      
â”‚       mode: online                                                            
â”‚       save_dir: .                                                             
â”‚       id: null                                                                
â”‚       name: ttlm-mnist1-v0                                                    
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ accelerator: gpu                                                        
â”‚       strategy: null                                                          
â”‚       devices: 1                                                              
â”‚       accumulate_grad_batches: 1                                              
â”‚       max_epochs: 100                                                         
â”‚       gradient_clip_val: null                                                 
â”‚       log_every_n_steps: 10                                                   
â”‚       limit_train_batches: 1.0                                                
â”‚       limit_val_batches: 1.0                                                  
â”‚       enable_model_summary: false                                             
â”‚       track_grad_norm: -1                                                     
â”‚                                                                               
â”œâ”€â”€ loader
â”‚   â””â”€â”€ batch_size: 50                                                          
â”‚       num_workers: 4                                                          
â”‚       pin_memory: true                                                        
â”‚       drop_last: true                                                         
â”‚                                                                               
â”œâ”€â”€ dataset
â”‚   â””â”€â”€ _name_: mnist                                                           
â”‚       permute: true                                                           
â”‚       val_split: 0.1                                                          
â”‚       seed: 42                                                                
â”‚                                                                               
â”œâ”€â”€ task
â”‚   â””â”€â”€ _name_: base                                                            
â”‚       loss: cross_entropy                                                     
â”‚       metrics:                                                                
â”‚       - accuracy                                                              
â”‚       torchmetrics: null                                                      
â”‚                                                                               
â”œâ”€â”€ optimizer
â”‚   â””â”€â”€ _name_: adamw                                                           
â”‚       lr: 0.0003                                                              
â”‚       weight_decay: 0.05                                                      
â”‚       betas:                                                                  
â”‚       - 0.9                                                                   
â”‚       - 0.999                                                                 
â”‚                                                                               
â”œâ”€â”€ scheduler
â”‚   â””â”€â”€ _name_: cosine_warmup                                                   
â”‚       num_warmup_steps: 10800                                                 
â”‚       num_training_steps: 108000                                              
â”‚                                                                               
â”œâ”€â”€ encoder
â”‚   â””â”€â”€ linear                                                                  
â”œâ”€â”€ decoder
â”‚   â””â”€â”€ _name_: sequence                                                        
â”‚       mode: pool                                                              
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ layer:                                                                  
â”‚         cell:                                                                 
â”‚           _name_: ttlm                                                        
â”‚           d_input: 384                                                        
â”‚           lr: 7.5e-05                                                         
â”‚         _name_: ttlm                                                          
â”‚         return_output: true                                                   
â”‚       _name_: model                                                           
â”‚       prenorm: false                                                          
â”‚       transposed: false                                                       
â”‚       n_layers: 1                                                             
â”‚       d_model: 384                                                            
â”‚       bidirectional: false                                                    
â”‚       residual: R                                                             
â”‚       pool: null                                                              
â”‚       norm: batch                                                             
â”‚       dropout: 0.2                                                            
â”‚       tie_dropout: false                                                      
â”‚       track_norms: true                                                       
â”‚       encoder: null                                                           
â”‚       decoder: null                                                           
â”‚                                                                               
â””â”€â”€ callbacks
    â””â”€â”€ learning_rate_monitor:                                                  
          logging_interval: step                                                
        timer:                                                                  
          step: true                                                            
          inter_step: false                                                     
          epoch: true                                                           
          val: true                                                             
        params:                                                                 
          total: true                                                           
          trainable: true                                                       
          fixed: true                                                           
        model_checkpoint:                                                       
          monitor: val/accuracy                                                 
          mode: max                                                             
          save_top_k: 1                                                         
          save_last: true                                                       
          dirpath: checkpoints/                                                 
          filename: val/accuracy                                                
          auto_insert_metric_name: false                                        
          verbose: true                                                         
        rich_model_summary:                                                     
          max_depth: 1                                                          
        rich_progress_bar:                                                      
          refresh_rate: 1                                                       
          leave: true                                                           
                                                                                
[rank: 0] Global seed set to 2222
wandb: Currently logged in as: yuqinzhou. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in ./wandb/run-20230815_095450-9wcbohs3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ttlm-mnist1-v0
wandb: â­ï¸ View project at https://wandb.ai/yuqinzhou/TNLM
wandb: ğŸš€ View run at https://wandb.ai/yuqinzhou/TNLM/runs/9wcbohs3
[2023-08-15 09:54:54,943][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.LearningRateMonitor>
[2023-08-15 09:54:54,944][__main__][INFO] - Instantiating callback <src.callbacks.timer.Timer>
[2023-08-15 09:54:54,947][__main__][INFO] - Instantiating callback <src.callbacks.params.ParamsLog>
[2023-08-15 09:54:54,948][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2023-08-15 09:54:54,954][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2023-08-15 09:54:54,955][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
NOTE: no dropout inside recurrent cell
SequenceLightningModule(
  (model): SequenceModel(
    (drop): Identity()
    (layers): ModuleList(
      (0): SequenceResidualBlock(
        (layer): RNN(
          (cell): TTLM()
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop): Dropout(p=0.2, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(384, 768, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
    )
    (norm): Identity()
  )
  (encoder): Linear(
    (0): Linear(in_features=1, out_features=384, bias=True)
  )
  (decoder): SequenceDecoder(
    (0): SequenceDecoder(
      (output_transform): Linear(in_features=384, out_features=10, bias=True)
    )
  )
)
Hyperparameter groups [{'lr': 7.5e-05, 'weight_decay': 0.0}]
[2023-08-15 09:54:57,110][__main__][INFO] - Optimizer group 0 | 8 tensors | lr 0.0003 | weight_decay 0.05
[2023-08-15 09:54:57,110][__main__][INFO] - Optimizer group 1 | 2 tensors | lr 7.5e-05 | weight_decay 0.0
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ   â”ƒ Name    â”ƒ Type            â”ƒ Params â”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ model   â”‚ SequenceModel   â”‚  591 K â”‚
â”‚ 1 â”‚ encoder â”‚ Linear          â”‚    768 â”‚
â”‚ 2 â”‚ decoder â”‚ SequenceDecoder â”‚  3.9 K â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 595 K                                                         
Non-trainable params: 0                                                         
Total params: 595 K                                                             
Total estimated model params size (MB): 2                                       
SLURM auto-requeueing enabled. Setting signal handlers.
[2023-08-15 09:54:57,131][__main__][INFO] - Loaded 'val' dataloader:         6000 examples |    120 steps
[2023-08-15 09:54:57,131][__main__][INFO] - Loaded 'test' dataloader:       10000 examples |    200 steps
[2023-08-15 09:55:01,261][__main__][INFO] - Loaded 'train' dataloader:      54000 examples |   1080 steps
Epoch 0, global step 1080: 'val/accuracy' reached 0.20650 (best 0.20650), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 0/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:53 â€¢       11.49it/s loss: 2.17 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.206 val/loss:  
                                                               2.185            
                                                               test/accuracy:   
                                                               0.197 test/loss: 
                                                               2.18             
                                                               train/accuracy:  
                                                               0.15 train/loss: 
                                                               2.248            
Epoch 1, global step 2160: 'val/accuracy' reached 0.32117 (best 0.32117), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 1/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:05:10 â€¢       10.99it/s loss: 1.84 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.321 val/loss:  
                                                               1.862            
                                                               test/accuracy:   
                                                               0.314 test/loss: 
                                                               1.873            
                                                               train/accuracy:  
                                                               0.297 train/loss:
                                                               1.937            
Epoch 2, global step 3240: 'val/accuracy' reached 0.36050 (best 0.36050), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 2/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:05:03 â€¢       11.93it/s loss: 1.75 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.361 val/loss:  
                                                               1.714            
                                                               test/accuracy:   
                                                               0.381 test/loss: 
                                                               1.715            
                                                               train/accuracy:  
                                                               0.342 train/loss:
                                                               1.816            
Epoch 3, global step 4320: 'val/accuracy' was not in top 1
Epoch 3/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:03:59 â€¢       11.86it/s loss: 1.58 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.257 val/loss:  
                                                               2.243            
                                                               test/accuracy:   
                                                               0.251 test/loss: 
                                                               2.259            
                                                               train/accuracy:  
                                                               0.397 train/loss:
                                                               1.674            
Epoch 4, global step 5400: 'val/accuracy' reached 0.39017 (best 0.39017), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 4/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:15 â€¢       11.51it/s loss: 1.63 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.39 val/loss:   
                                                               1.694            
                                                               test/accuracy:   
                                                               0.389 test/loss: 
                                                               1.69             
                                                               train/accuracy:  
                                                               0.426 train/loss:
                                                               1.618            
Epoch 5, global step 6480: 'val/accuracy' was not in top 1
Epoch 5/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:12 â€¢       12.18it/s loss: 1.54 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.346 val/loss:  
                                                               1.837            
                                                               test/accuracy:   
                                                               0.336 test/loss: 
                                                               1.832            
                                                               train/accuracy:  
                                                               0.461 train/loss:
                                                               1.552            
Epoch 6, global step 7560: 'val/accuracy' reached 0.51767 (best 0.51767), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 6/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:08 â€¢       11.88it/s loss: 1.3 v_num: 
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.518 val/loss:  
                                                               1.345            
                                                               test/accuracy:   
                                                               0.528 test/loss: 
                                                               1.347            
                                                               train/accuracy:  
                                                               0.515 train/loss:
                                                               1.415            
Epoch 7, global step 8640: 'val/accuracy' was not in top 1
Epoch 7/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:26 â€¢       11.78it/s loss: 1.16 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.516 val/loss:  
                                                               1.392            
                                                               test/accuracy:   
                                                               0.524 test/loss: 
                                                               1.363            
                                                               train/accuracy:  
                                                               0.576 train/loss:
                                                               1.257            
Epoch 8, global step 9720: 'val/accuracy' was not in top 1
Epoch 8/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:33 â€¢       11.53it/s loss: 1.11 v_num:
                                     0:00:00                   ohs3             
                                                               val/accuracy:    
                                                               0.469 val/loss:  
                                                               1.459            
                                                               test/accuracy:   
                                                               0.478 test/loss: 
                                                               1.441            
                                                               train/accuracy:  
                                                               0.613 train/loss:
                                                               1.158            
Epoch 9, global step 10800: 'val/accuracy' was not in top 1
Epoch 9/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:25 â€¢       12.19it/s loss: 0.999      
                                     0:00:00                   v_num: ohs3      
                                                               val/accuracy:    
                                                               0.316 val/loss:  
                                                               2.014            
                                                               test/accuracy:   
                                                               0.309 test/loss: 
                                                               1.995            
                                                               train/accuracy:  
                                                               0.652 train/loss:
                                                               1.065            
Epoch 10, global step 11880: 'val/accuracy' reached 0.55483 (best 0.55483), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 10/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:25 â€¢       12.12it/s loss: 0.849     
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.555 val/loss: 
                                                                1.482           
                                                                test/accuracy:  
                                                                0.577 test/loss:
                                                                1.44            
                                                                train/accuracy: 
                                                                0.698           
                                                                train/loss:     
                                                                0.941           
Epoch 11, global step 12960: 'val/accuracy' reached 0.71117 (best 0.71117), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 11/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:28 â€¢       11.96it/s loss: 0.764     
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.711 val/loss: 
                                                                0.887           
                                                                test/accuracy:  
                                                                0.72 test/loss: 
                                                                0.876           
                                                                train/accuracy: 
                                                                0.735           
                                                                train/loss:     
                                                                0.849           
Epoch 12, global step 14040: 'val/accuracy' reached 0.71500 (best 0.71500), saving model to '/home/qvk729/Master_thesis/outputs/2023-08-15/09-54-48-622458/checkpoints/val/accuracy.ckpt' as top 1
Epoch 12/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:29 â€¢       11.27it/s loss: 0.814     
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.715 val/loss: 
                                                                0.872           
                                                                test/accuracy:  
                                                                0.717 test/loss:
                                                                0.863           
                                                                train/accuracy: 
                                                                0.762           
                                                                train/loss:     
                                                                0.767           
Epoch 13, global step 15120: 'val/accuracy' was not in top 1
Epoch 13/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:36 â€¢       11.51it/s loss: 2.19      
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.191 val/loss: 
                                                                2.201           
                                                                test/accuracy:  
                                                                0.19 test/loss: 
                                                                2.203           
                                                                train/accuracy: 
                                                                0.567           
                                                                train/loss:     
                                                                1.321           
Epoch 14, global step 16200: 'val/accuracy' was not in top 1
Epoch 14/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:20 â€¢       11.65it/s loss: 2.14      
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.199 val/loss: 
                                                                2.145           
                                                                test/accuracy:  
                                                                0.193 test/loss:
                                                                2.143           
                                                                train/accuracy: 
                                                                0.211           
                                                                train/loss:     
                                                                2.169           
Epoch 15, global step 17280: 'val/accuracy' was not in top 1
Epoch 15/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:25 â€¢       11.67it/s loss: 2.09      
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.221 val/loss: 
                                                                2.099           
                                                                test/accuracy:  
                                                                0.222 test/loss:
                                                                2.099           
                                                                train/accuracy: 
                                                                0.218           
                                                                train/loss:     
                                                                2.119           
Epoch 16, global step 18360: 'val/accuracy' was not in top 1
Epoch 16/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:11 â€¢       11.23it/s loss: 2.09      
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.23 val/loss:  
                                                                2.082           
                                                                test/accuracy:  
                                                                0.226 test/loss:
                                                                2.086           
                                                                train/accuracy: 
                                                                0.221           
                                                                train/loss:     
                                                                2.092           
Epoch 17, global step 19440: 'val/accuracy' was not in top 1
Epoch 17/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:26 â€¢       11.67it/s loss: 2.1 v_num:
                                      0:00:00                   ohs3            
                                                                val/accuracy:   
                                                                0.221 val/loss: 
                                                                2.072           
                                                                test/accuracy:  
                                                                0.212 test/loss:
                                                                2.074           
                                                                train/accuracy: 
                                                                0.225           
                                                                train/loss:     
                                                                2.079           
Epoch 18, global step 20520: 'val/accuracy' was not in top 1
Epoch 18/99 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1400/1400 0:04:40 â€¢       11.57it/s loss: 2.06      
                                      0:00:00                   v_num: ohs3     
                                                                val/accuracy:   
                                                                0.228 val/loss: 
                                                                2.073           
                                                                test/accuracy:  
                                                                0.225 test/loss:
                                                                2.081           
                                                                train/accuracy: 
                                                                0.225           
                                                                train/loss:     
                                                                2.073           
