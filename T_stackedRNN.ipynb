{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from src.models.baselines.lstm import TorchLSTM\n",
    "from src.models.baselines.gru import TorchGRU\n",
    "from src.models.sequence.base import SequenceModule\n",
    "# from src.models.sequence.modules.s4block import S4Block\n",
    "# from src.dataloaders.audio import mu_law_decode, linear_decode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized transform (transforms to tensor, here you can normalize, perform Data Augmentation etc.)\n",
    "my_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download data\n",
    "mnist_train = torchvision.datasets.MNIST('data', train = True, download=True, transform=my_transform)\n",
    "mnist_test = torchvision.datasets.MNIST('data', train = False, download=True, transform=my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. original images shape: torch.Size([64, 1, 28, 28])\n",
      "2. reshaped images shape: torch.Size([64, 28, 28]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Create a train_loader to select a batch from it\n",
    "train_loader_example = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "# Taking a single batch of the images\n",
    "images, labels = next(iter(train_loader_example))\n",
    "print('1. original images shape:', images.shape)\n",
    "\n",
    "# Remove channel from shape\n",
    "images = images.reshape(-1, 28, 28)\n",
    "print('2. reshaped images shape:', images.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedRNN(SequenceModule):\n",
    "    \"\"\"\n",
    "    StackedRNN with skip connections:\n",
    "        Input (d_model) -> RNN_1 (d_hidden) -> Linear (d_hidden, d_hidden) -> Output\n",
    "        [Input, RNN_1] (d_model + d_hidden) -> RNN_2 (d_hidden) -> Linear (d_hidden, d_hidden) -> += Output\n",
    "        [Input, RNN_2] (d_model + d_hidden) -> RNN_3 (d_hidden) -> Linear (d_hidden, d_hidden) -> += Output\n",
    "    ...\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def d_output(self):\n",
    "        return self.d_model if self.output_linear else self.d_hidden\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        d_hidden,\n",
    "        n_layers,\n",
    "        learn_h0=False,\n",
    "        rnn_type='gru',\n",
    "        skip_connections=False,\n",
    "        weight_norm=False,\n",
    "        dropout=0.0,\n",
    "        output_linear=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_hidden = d_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.learn_h0 = learn_h0\n",
    "        self.skip_connections = skip_connections\n",
    "        self.weight_norm = torch.nn.utils.weight_norm if weight_norm else lambda x: x\n",
    "\n",
    "        self.output_linear = output_linear\n",
    "        self.rnn_layers = torch.nn.ModuleList()\n",
    "        self.lin_layers = torch.nn.ModuleList()\n",
    "        self.dropout_layers = torch.nn.ModuleList()\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == 'lstm':\n",
    "            RNN = TorchLSTM\n",
    "        elif rnn_type == 'gru':\n",
    "            RNN = TorchGRU\n",
    "        else:\n",
    "            raise ValueError('rnn_type must be lstm or gru')\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            ## create ModuleList by literations\n",
    "            if i == 0:\n",
    "                self.rnn_layers.append(\n",
    "                    RNN(d_model=d_model, d_hidden=d_hidden, n_layers=1, learn_h0=learn_h0),\n",
    "                )\n",
    "            else:\n",
    "                if skip_connections:\n",
    "                    self.rnn_layers.append(\n",
    "                        RNN(d_model=d_model + d_hidden, d_hidden=d_hidden, n_layers=1, learn_h0=learn_h0),\n",
    "                    )\n",
    "                else:\n",
    "                    self.rnn_layers.append(\n",
    "                        RNN(d_model=d_hidden, d_hidden=d_hidden, n_layers=1, learn_h0=learn_h0),\n",
    "                    )\n",
    "\n",
    "            if skip_connections:\n",
    "                self.lin_layers.append(self.weight_norm(torch.nn.Linear(d_hidden, d_hidden)))\n",
    "            else:\n",
    "                self.lin_layers.append(torch.nn.Identity())\n",
    "\n",
    "            # If dropout, only apply to the outputs of RNNs that are not the last one (like torch's LSTM)\n",
    "            if dropout > 0.0 and i < n_layers - 1:\n",
    "                self.dropout_layers.append(torch.nn.Dropout(dropout))\n",
    "            else:\n",
    "                self.dropout_layers.append(torch.nn.Identity())\n",
    "\n",
    "        if output_linear:\n",
    "            self.output_layer = self.weight_norm(torch.nn.Linear(d_hidden, d_model))\n",
    "        else:\n",
    "            self.output_layer = torch.nn.Identity()\n",
    "\n",
    "        # Apply weight norm to all the RNN layers\n",
    "        for rnn in self.rnn_layers:\n",
    "            # Find all Linear layers in the RNN\n",
    "            for name, module in rnn.named_modules():\n",
    "                if isinstance(module, torch.nn.Linear):\n",
    "                    setattr(rnn, name, self.weight_norm(module))\n",
    "\n",
    "        # Use orthogonal initialization for W_hn if using GRU (weight_hh_l[0])\n",
    "        if rnn_type == 'gru':\n",
    "            for rnn in self.rnn_layers:\n",
    "                torch.nn.init.orthogonal_(rnn.weight_hh_l0[2 * d_hidden:].data)\n",
    "\n",
    "    \"\"\"Create initial state for a batch of inputs.\"\"\"\n",
    "    def default_state(self, *batch_shape, device=None):\n",
    "        return [\n",
    "            rnn.default_state(*batch_shape, device=device)\n",
    "            for rnn in self.rnn_layers\n",
    "        ]\n",
    "\n",
    "    def forward(self, inputs, *args, state=None, **kwargs):\n",
    "        outputs = inputs\n",
    "        prev_states = [None] * len(self.rnn_layers) if state is None else state\n",
    "        next_states = []\n",
    "        out = 0.\n",
    "        for rnn, prev_state, lin, dropout in zip(self.rnn_layers, prev_states, self.lin_layers, self.dropout_layers):\n",
    "            # Run RNN on inputs \n",
    "            outputs, state = rnn(outputs, prev_state)\n",
    "            next_states.append(state)\n",
    "            # <pre_state> e.g., prev_state is h_0 for for layer 0\n",
    "            # <outputs> the whole last RNN layer\n",
    "            # <state>: the final hidden states at the current layer)\n",
    "\n",
    "\n",
    "            outputs = dropout(outputs)\n",
    "            z = lin(outputs)\n",
    "            if self.skip_connections:\n",
    "                # If skip connections, add the outputs of all the RNNs to the outputs\n",
    "                out += z\n",
    "                # Feed in the outputs of the previous RNN, and the original inputs to the next RNN\n",
    "                outputs = torch.cat([outputs, inputs], dim=-1)\n",
    "            else:\n",
    "                out = z\n",
    "                outputs = z\n",
    "\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        return out, next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_states = [None] * 3\n",
    "prev_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackedRNN(\n",
      "  (rnn_layers): ModuleList(\n",
      "    (0): TorchGRU(28, 100, batch_first=True)\n",
      "    (1-5): 5 x TorchGRU(100, 100, batch_first=True)\n",
      "  )\n",
      "  (lin_layers): ModuleList(\n",
      "    (0-5): 6 x Identity()\n",
      "  )\n",
      "  (dropout_layers): ModuleList(\n",
      "    (0-5): 6 x Identity()\n",
      "  )\n",
      "  (output_layer): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "StackedRNN_example = StackedRNN(d_model = 28, d_hidden =100, n_layers = 6)\n",
    "print(StackedRNN_example)\n",
    "\n",
    "\n",
    "# Making log predictions:\n",
    "out = StackedRNN_example(images, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342000\n"
     ]
    }
   ],
   "source": [
    "# for parameter in StackedRNN_example.parameters():\n",
    "#     print(parameter.size())\n",
    "pytorch_total_params = sum(p.numel() for p in StackedRNN_example.parameters() if p.requires_grad)\n",
    "print(pytorch_total_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
