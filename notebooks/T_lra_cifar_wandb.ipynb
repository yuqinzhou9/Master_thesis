{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.13.0\n",
      "torchvisio: 0.14.0\n",
      "torchaudio: 0.13.0\n",
      "torchtext: 0.14.0\n",
      "torchdata: 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"torch: {torch.__version__}\")\n",
    "import torchvision\n",
    "print(f\"torchvisio: {torchvision.__version__}\")\n",
    "import torchaudio\n",
    "print(f\"torchaudio: {torchaudio.__version__}\")\n",
    "import torchtext\n",
    "print(f\"torchtext: {torchtext.__version__}\")\n",
    "import torchdata\n",
    "print(f\"torchdata: {torchdata.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from src.utils.optim.schedulers import CosineWarmup\n",
    "from src.models.sequence.rnns.rnn import RNN\n",
    "\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# import wandb\n",
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n"
     ]
    }
   ],
   "source": [
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device available now:', device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# Dataset\n",
    "parser.add_argument('--dataset', default='cifar10', choices=['cifar10', 'listops', 'imdb', 'aan', 'pathfinder'], type=str, help='Dataset')\n",
    "###! imdb refers to TEXT, ann refers to RETRIEVAL \n",
    "parser.add_argument('--grayscale', action='store_true', help='Use grayscale CIFAR10')\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "parser.add_argument('--num_workers', default=0, type=int, help='Number of workers to use for dataloader')\n",
    "parser.add_argument('--batch_size', default=50, type=int, help='Batch size')\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "parser.add_argument('--lr', default= 0.01, type=float, help='Learning rate') # 0.01\n",
    "parser.add_argument('--lr_factor', default= 0.25, type=float, help='Factor of Learning rate') \n",
    "parser.add_argument('--weight_decay', default=0.05, type=float, help='Weight decay')\n",
    "\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "parser.add_argument('--epochs', default=200, type=float, help='Training epochs')\n",
    "\n",
    "\n",
    "# Model\n",
    "parser.add_argument('--n_layers', default=2, type=int, help='Number of layers') #6\n",
    "parser.add_argument('--d_model', default=128, type=int, help='Model dimension') #512\n",
    "parser.add_argument('--d_hidden', default=196, type=int, help='Hidden (state) dimension ') #384\n",
    "parser.add_argument('--dropout', default=0.1, type=float, help='Dropout')\n",
    "parser.add_argument('--prenorm', action='store_false', help='Prenorm')\n",
    "parser.add_argument('--norm', default= 'BN', choices=['LN', 'BN'], help='Norm types')\n",
    "parser.add_argument('--cell', default= 'rnn', type=str, help='RNN\\'s cell')\n",
    "\n",
    "\n",
    "# General\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='Resume from checkpoint')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=50, cell='rnn', d_hidden=196, d_model=128, dataset='cifar10', dropout=0.1, epochs=200, grayscale=False, lr=0.01, lr_factor=0.25, n_layers=2, norm='BN', num_workers=0, prenorm=True, resume=False, weight_decay=0.05)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = RNN(d_input = 3, d_model = 5, lr = args.lr * args.lr_factor, cell = \"rnn\", return_output=True, transposed=False, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in d.parameters():\n",
    "#     print(i._optim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(train, val_split):\n",
    "    train_len = int(len(train) * (1.0-val_split))\n",
    "    train, val = torch.utils.data.random_split(\n",
    "        train,\n",
    "        (train_len, len(train) - train_len),\n",
    "        generator=torch.Generator().manual_seed(42),\n",
    "    )\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == 'cifar10':\n",
    "    if args.grayscale:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=122.6 / 255.0, std=61.0 / 255.0),\n",
    "            transforms.Lambda(lambda x: x.view(1, 1024).t())\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            transforms.Lambda(lambda x: x.view(3, 1024).t())\n",
    "        ])\n",
    "    \n",
    "    # S4 is trained on sequences with no data augmentation!\n",
    "    transform_train = transform_test = transform\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=True, download=True, transform=transform_train)\n",
    "    trainset, _ = split_train_val(trainset, val_split=0.1)\n",
    "\n",
    "    valset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=True, download=True, transform=transform_test)\n",
    "    _, valset = split_train_val(valset, val_split=0.1)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=False, download=True, transform=transform_test)\n",
    "\n",
    "    d_input = 3 if not args.grayscale else 1\n",
    "    d_output = 10\n",
    "\n",
    "else: raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1024, 3]) tensor([8, 0, 7, 9, 3, 1, 3, 0, 1, 3, 4, 3, 4, 7, 6, 7, 1, 1, 4, 7, 3, 1, 9, 8,\n",
      "        7, 9, 0, 8, 8, 5, 5, 9, 3, 5, 4, 5, 9, 3, 2, 3, 6, 5, 8, 4, 0, 0, 9, 7,\n",
      "        1, 9])\n"
     ]
    }
   ],
   "source": [
    "# Taking a single batch of the images\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.size(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3817,  0.6104,  1.3880],\n",
       "         [ 0.4205,  0.6498,  1.4270],\n",
       "         [ 0.4205,  0.6498,  1.4270],\n",
       "         ...,\n",
       "         [-1.3823, -1.1399, -0.8362],\n",
       "         [-1.4017, -1.1792, -0.8167],\n",
       "         [-0.8007, -0.5892, -0.2118]],\n",
       "\n",
       "        [[ 1.1378,  1.7511,  2.3830],\n",
       "         [ 0.9827,  1.6528,  2.2660],\n",
       "         [ 0.9439,  1.6331,  2.2660],\n",
       "         ...,\n",
       "         [-1.7118, -2.1429, -1.6556],\n",
       "         [-1.6924, -2.1233, -1.5971],\n",
       "         [-1.6924, -2.1233, -1.7141]],\n",
       "\n",
       "        [[-0.0835,  1.1611,  2.1684],\n",
       "         [-0.0835,  1.1414,  2.1489],\n",
       "         [-0.0641,  1.1808,  2.1879],\n",
       "         ...,\n",
       "         [ 0.9439,  0.8464,  0.3149],\n",
       "         [ 1.0021,  0.9054,  0.3930],\n",
       "         [ 1.1184,  0.9644,  0.4710]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.8977,  0.4138,  1.8953],\n",
       "         [-0.8783,  0.4334,  1.9538],\n",
       "         [-0.8783,  0.4334,  1.9733],\n",
       "         ...,\n",
       "         [ 1.4867, -0.2352, -0.9727],\n",
       "         [ 1.4673, -0.2942, -1.0898],\n",
       "         [ 1.4867, -0.2549, -1.1093]],\n",
       "\n",
       "        [[ 0.5756,  0.9251,  1.0368],\n",
       "         [ 0.5368,  0.8858,  0.9978],\n",
       "         [ 0.5368,  0.8858,  0.9978],\n",
       "         ...,\n",
       "         [ 0.6919,  0.3154, -0.3874],\n",
       "         [ 0.8082,  0.4334, -0.2704],\n",
       "         [ 0.8276,  0.4531, -0.2899]],\n",
       "\n",
       "        [[ 1.5836,  1.8495,  2.3245],\n",
       "         [ 1.6224,  1.8495,  2.2855],\n",
       "         [ 1.6805,  1.8691,  2.2855],\n",
       "         ...,\n",
       "         [ 0.2654,  0.1188,  0.3345],\n",
       "         [ 0.2461,  0.0794,  0.3345],\n",
       "         [ 0.2654,  0.0991,  0.3540]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 900)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset), len(trainloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNbased(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output,\n",
    "        lr,\n",
    "        cell='rnn',\n",
    "        d_model=256,\n",
    "        d_hidden=128,\n",
    "        n_layers=2,\n",
    "        dropout=0.2,\n",
    "        prenorm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder (d_input = 1 for grayscale and 3 for RGB) (like embedding layer)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        self.FFNs = nn.ModuleList()\n",
    "\n",
    "        for _ in range(n_layers):\n",
    "            self.layers.append(\n",
    "                RNN(d_input = d_model, d_model = d_hidden, lr = lr, cell = cell, return_output=True, transposed=True, dropout=0)\n",
    "            )\n",
    "            # self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.norms.append(nn.BatchNorm1d(d_model)) \n",
    "            self.dropouts.append(nn.Dropout1d(dropout))\n",
    "            self.FFNs.append(nn.Sequential(nn.Conv1d(d_hidden, d_model*2, kernel_size= 1 ), nn.GLU(dim=-2))  #                \n",
    "                                 )\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        \n",
    "\n",
    "        for layer, norm, dropout, FFN in zip(self.layers, self.norms, self.dropouts, self.FFNs):\n",
    "            ''' Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L) '''\n",
    "\n",
    "            \n",
    "            z = x #(B, d_model, L) -> (B, d_model, L) \n",
    "            if self.prenorm:\n",
    "                # Prenorm (BN)\n",
    "                z = norm(z) # (B, d_model, L) -> (B, d_model, L) \n",
    "\n",
    "            # Apply recurrence: we ignore the state input and output\n",
    "            z, _ = layer(z) #(B, d_model, L) -> (B, d_model, L) (note that we transpose the input inside the layer)\n",
    "\n",
    "            \n",
    "            # Dropout on the output of the MLP \n",
    "            z = dropout(z) #(B, d_model, L) -> (B, d_model, L) for dropout1d\n",
    "            \n",
    "            # MLP +GLP\n",
    "            z = FFN(z) #(B, d_model, L) -> (B, d_model, L) for conv1d\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x  #(B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Post-norm (BN)\n",
    "                x = norm(x) #(B, d_model, L) -> (B, d_model, L)\n",
    "                \n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = x.mean(dim=1) # (B, L, d_model) -> (B, d_model)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNbased(\n",
      "  (encoder): Linear(in_features=3, out_features=128, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0): RNN(\n",
      "      (cell): RNNCell(\n",
      "        (W_hx): Linear(in_features=128, out_features=196, bias=False)\n",
      "        (activate): Tanh()\n",
      "        (W_hh): Linear(in_features=196, out_features=196, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): RNN(\n",
      "      (cell): RNNCell(\n",
      "        (W_hx): Linear(in_features=128, out_features=196, bias=False)\n",
      "        (activate): Tanh()\n",
      "        (W_hh): Linear(in_features=196, out_features=196, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropouts): ModuleList(\n",
      "    (0): Dropout1d(p=0.1, inplace=False)\n",
      "    (1): Dropout1d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (FFNs): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv1d(196, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): GLU(dim=-2)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv1d(196, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): GLU(dim=-2)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "example = RNNbased(d_input=d_input, \n",
    "                   d_output=d_output, \n",
    "                   cell='rnn',\n",
    "                   lr = args.lr * args.lr_factor,\n",
    "                   d_model=args.d_model, \n",
    "                   d_hidden=args.d_hidden, \n",
    "                   n_layers=args.n_layers, \n",
    "                   dropout=args.dropout, \n",
    "                   prenorm=args.prenorm)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_optimizer(model, lr, weight_decay, epochs):\n",
    "    # All parameters in the model\n",
    "    all_parameters = list(model.parameters())\n",
    "\n",
    "    # General parameters don't contain the special _optim key\n",
    "    params = [p for p in all_parameters if not hasattr(p, \"_optim\")]\n",
    "\n",
    "    # Create an optimizer with the general parameters\n",
    "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Add parameters with special hyperparameters\n",
    "    hps = [getattr(p, \"_optim\") for p in all_parameters if hasattr(p, \"_optim\")]\n",
    "        # e.g., p could be {'weight_decay': 0.0, 'lr': 1e-07}\n",
    "    hps = [\n",
    "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
    "    ]  # Unique dicts \n",
    "    \n",
    "    \n",
    "    for hp in hps: \n",
    "        params = [p for p in all_parameters if getattr(p, \"_optim\", None) == hp] ## select parameter matrices that have \"_optim\" and assign \"_optim = None\" to matrices that do not have\n",
    "        optimizer.add_param_group(\n",
    "            {\"params\": params, **hp} ## <**hp> referes to hyperparameters e.g., {'weight_decay': 0.0}\n",
    "        )\n",
    "\n",
    "    # Create a lr scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    scheduler = CosineWarmup(optimizer, T_max = epochs, eta_min= 1e-7, warmup_step= int(epochs * 0.1) + 1) \n",
    "\n",
    "    ''' Print optimizer info '''\n",
    "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
    "    \n",
    "    \n",
    "    for i, g in enumerate(optimizer.param_groups):\n",
    "        group_hps = {k: g.get(k, None) for k in keys}\n",
    "        print(' | '.join([\n",
    "            f\"Optimizer group {i}\",\n",
    "            f\"{len(g['params'])} tensors\",\n",
    "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
    "\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer group 0 | 12 tensors | lr 0.0004761904761904762 | weight_decay 0.05\n",
      "Optimizer group 1 | 4 tensors | lr 0.00011904761904761905 | weight_decay 0.0\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "optimizer, scheduler = setup_optimizer(\n",
    "    example, lr=args.lr, weight_decay=args.weight_decay, epochs=args.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.utils.optim.schedulers.CosineWarmup at 0x7f7b11d42490>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "LEARNING_RATE = args.lr\n",
    "EPOCHS = args.epochs\n",
    "STEPS_IN_EPOCH = 1\n",
    "\n",
    "# Set model and optimizer\n",
    "model = torch.nn.Linear(2, 1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay= args.weight_decay)\n",
    "\n",
    "# Define your scheduler here as described above\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "scheduler = CosineWarmup(optimizer, T_max = args.epochs, eta_min= 1e-7, warmup_step= 2) \n",
    "\n",
    "# Get learning rates as each training step\n",
    "learning_rates = []\n",
    "\n",
    "for i in range(EPOCHS*STEPS_IN_EPOCH):\n",
    "    optimizer.step()\n",
    "    learning_rates.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "\n",
    "# Visualize learinig rate scheduler\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "ax.plot(range(EPOCHS*STEPS_IN_EPOCH), \n",
    "        learning_rates,\n",
    "        marker='o', \n",
    "        color='black')\n",
    "ax.set_xlim([0, EPOCHS*STEPS_IN_EPOCH])\n",
    "ax.set_ylim([0, LEARNING_RATE + 0.0001])\n",
    "ax.set_xlabel('Steps')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(STEPS_IN_EPOCH))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00025"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3 * 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.005"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(model, optimizer,  criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    print_every = 50\n",
    "\n",
    "    for batch_idx, (inputs, targets) in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        wandb.log({\"Train/Batch loss\": train_loss/(batch_idx+1)})\n",
    "\n",
    "        if (batch_idx % print_every) == 0:\n",
    "            print(f\"Batch: {batch_idx}, Avg: {train_loss/(batch_idx+1)}\")\n",
    "        \n",
    "        pbar.set_description(\n",
    "            'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "            (batch_idx, len(trainloader), train_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "        )\n",
    "    return train_loss/(batch_idx+1)\n",
    "\n",
    "\n",
    "\n",
    "def eval(model, criterion, dataloader):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(dataloader))\n",
    "        for batch_idx, (inputs, targets) in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "            pbar.set_description(\n",
    "                'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "                (batch_idx, len(dataloader), eval_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "            )\n",
    "            \n",
    "        return 100.*correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/checkpoint_5pmj4d8b.pth\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "run_id = wandb.util.generate_id()\n",
    "CHECKPOINT_PATH = f'./checkpoint/checkpoint_{run_id}.pth'\n",
    "print(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/zhouyuqin/Desktop/Thesis/experiments/wandb/run-20230512_191758-5pmj4d8b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yuqinzhou/test/runs/5pmj4d8b' target=\"_blank\">RNN_Vanilla_0</a></strong> to <a href='https://wandb.ai/yuqinzhou/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yuqinzhou/test' target=\"_blank\">https://wandb.ai/yuqinzhou/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yuqinzhou/test/runs/5pmj4d8b' target=\"_blank\">https://wandb.ai/yuqinzhou/test/runs/5pmj4d8b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model / ...\n",
      "Optimizer group 0 | 12 tensors | lr 0.0004761904761904762 | weight_decay 0.05\n",
      "Optimizer group 1 | 4 tensors | lr 0.00011904761904761905 | weight_decay 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 2.418267011642456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 2.1103724848990346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 2.0617622266901603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (137/900) | Loss: 2.045 | Acc: 23.232% (1603/6900): : 138it [06:23,  2.78s/it]\n",
      "Epoch: 0:   0%|          | 0/200 [06:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     pbar\u001b[39m.\u001b[39mset_description(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m | Val acc: \u001b[39m\u001b[39m%1.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (epoch, val_acc))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m==> Training...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m epoch_loss \u001b[39m=\u001b[39m train(model \u001b[39m=\u001b[39;49m model,optimizer \u001b[39m=\u001b[39;49m optimizer, criterion \u001b[39m=\u001b[39;49m nn\u001b[39m.\u001b[39;49mCrossEntropyLoss())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m\"\u001b[39m: epoch, \u001b[39m\"\u001b[39m\u001b[39mTrain/Epoch Loss\u001b[39m\u001b[39m\"\u001b[39m: epoch_loss})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m==> Validating...\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb Cell 26\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zhouyuqin/Desktop/Thesis/experiments/T_lra_cifar_wandb.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_runs = 1\n",
    "for run in range(total_runs):\n",
    "    wandb.init(\n",
    "        id= run_id,\n",
    "        project=\"test\", \n",
    "        # Model + Cell + Run\n",
    "        name=f\"RNN_Vanilla_{run}\", \n",
    "        config=args,\n",
    "        resume = 'allow')\n",
    "    \n",
    "    # defining model (resume or not)\n",
    "    if not wandb.run.resumed:\n",
    "        print('==> Building model / ...')\n",
    "        model = RNNbased(d_input=d_input, \n",
    "                    d_output=d_output, \n",
    "                    lr = args.lr * args.lr_factor,\n",
    "                    cell='rnn',\n",
    "                    d_model=args.d_model, \n",
    "                    d_hidden=args.d_hidden, \n",
    "                    n_layers=args.n_layers, \n",
    "                    dropout=args.dropout, \n",
    "                    prenorm=args.prenorm)\n",
    "        \n",
    "        optimizer, scheduler = setup_optimizer(model, lr=args.lr, weight_decay=args.weight_decay, epochs=args.epochs)\n",
    "        # optimizer = optim.AdamW(model.parameters(), lr= args.lr, weight_decay= args.weight_decay)\n",
    "        # scheduler = CosineWarmup(optimizer, T_max = args.epochs, eta_min= 1e-7, warmup_step= int(args.epochs * 0.1) + 1) \n",
    "        \n",
    "    else:\n",
    "        print('==> Resuming from checkpoint...')\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH) #not use wandb.restore('checkpoint.tar') because of encoding error\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_acc = checkpoint['acc']\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        \n",
    "    model = model.to(device)\n",
    "\n",
    "    \n",
    "\n",
    "    ## defining training, validating and testing\n",
    "    pbar = tqdm(range(start_epoch, args.epochs))\n",
    "    for epoch in pbar:\n",
    "        wandb.log({\"Epoch\": epoch, \"lr_general\": scheduler.get_last_lr()[0]}) #record general lr for the current lr\n",
    "        wandb.log({\"Epoch\": epoch, \"lr_special\": scheduler.get_last_lr()[1]}) #record special lr for the current lr\n",
    "        \n",
    "        if epoch == 0:\n",
    "            pbar.set_description('Epoch: %d' % (epoch))\n",
    "        else:\n",
    "            pbar.set_description('Epoch: %d | Val acc: %1.3f' % (epoch, val_acc))\n",
    "\n",
    "\n",
    "        print('==> Training...')\n",
    "        epoch_loss = train(model = model,optimizer = optimizer, criterion = nn.CrossEntropyLoss())\n",
    "        wandb.log({\"Epoch\": epoch, \"Train/Epoch Loss\": epoch_loss})\n",
    "\n",
    "\n",
    "        print('==> Validating...')\n",
    "        val_acc = eval(model = model, criterion = nn.CrossEntropyLoss(), dataloader = valloader)\n",
    "        wandb.log({\"Epoch\": epoch, \"Val/Val acc\": val_acc})\n",
    "        \n",
    "        scheduler.step() #update lr\n",
    "        \n",
    "        #Save checkpoints\n",
    "        if val_acc > best_acc:\n",
    "            state = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(), # record lr for the next epoch\n",
    "                'acc': val_acc,\n",
    "                'epoch': epoch,\n",
    "\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "                \n",
    "            torch.save(state, CHECKPOINT_PATH)\n",
    "            # wandb.save(CHECKPOINT_PATH)\n",
    "            best_acc = val_acc\n",
    "    \n",
    "    print('==> Testing...')\n",
    "    test_acc = eval(model = model, criterion = nn.CrossEntropyLoss(), dataloader = testloader)\n",
    "    wandb.log({\"Test/Test acc\": test_acc})\n",
    "    \n",
    "    # Mark the run as finished\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
