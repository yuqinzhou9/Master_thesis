{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhouyuqin/Desktop/Thesis/experiments/state-spaces\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.utils.optim.schedulers import CosineWarmup\n",
    "from src.models.sequence.rnns.cells.basic import RNNCell\n",
    "from src.models.sequence.rnns.cells import CellBase\n",
    "from src.models.sequence.rnns.rnn import RNN\n",
    "\n",
    "# from models.s4.s4 import S4\n",
    "from models.s4.s4d import S4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n"
     ]
    }
   ],
   "source": [
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device available now:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 1234):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# Optimizer\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')\n",
    "parser.add_argument('--weight_decay', default=0.05, type=float, help='Weight decay')\n",
    "\n",
    "\n",
    "# Scheduler\n",
    "# parser.add_argument('--patience', default=10, type=float, help='Patience for learning rate scheduler')\n",
    "parser.add_argument('--epochs', default=10, type=float, help='Training epochs')\n",
    "\n",
    "\n",
    "# Dataset\n",
    "parser.add_argument('--dataset', default='cifar10', choices=['mnist', 'cifar10'], type=str, help='Dataset')\n",
    "parser.add_argument('--grayscale', action='store_true', help='Use grayscale CIFAR10')\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "parser.add_argument('--num_workers', default=0, type=int, help='Number of workers to use for dataloader')\n",
    "parser.add_argument('--batch_size', default=64, type=int, help='Batch size')\n",
    "\n",
    "\n",
    "# Model\n",
    "parser.add_argument('--n_layers', default=2, type=int, help='Number of layers')\n",
    "parser.add_argument('--d_model', default=128, type=int, help='Model dimension')\n",
    "parser.add_argument('--dropout', default=0.1, type=float, help='Dropout')\n",
    "parser.add_argument('--prenorm', action='store_true', help='Prenorm')\n",
    "\n",
    "\n",
    "# General\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='Resume from checkpoint')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing cifar10 data..\n",
      "Namespace(batch_size=64, d_model=128, dataset='cifar10', dropout=0.1, epochs=10, grayscale=False, lr=0.001, n_layers=2, num_workers=0, prenorm=False, resume=False, weight_decay=0.05)\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print(f'==> Preparing {args.dataset} data..')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.resume"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(train, val_split):\n",
    "    train_len = int(len(train) * (1.0-val_split))\n",
    "    train, val = torch.utils.data.random_split(\n",
    "        train,\n",
    "        (train_len, len(train) - train_len),\n",
    "        generator=torch.Generator().manual_seed(42),\n",
    "    )\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == 'cifar10':\n",
    "\n",
    "    if args.grayscale:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=122.6 / 255.0, std=61.0 / 255.0),\n",
    "            transforms.Lambda(lambda x: x.view(1, 1024).t())\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "            transforms.Lambda(lambda x: x.view(3, 1024).t())\n",
    "        ])\n",
    "\n",
    "    # S4 is trained on sequences with no data augmentation!\n",
    "    transform_train = transform_test = transform\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=True, download=True, transform=transform_train)\n",
    "    trainset, _ = split_train_val(trainset, val_split=0.1)\n",
    "\n",
    "    valset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=True, download=True, transform=transform_test)\n",
    "    _, valset = split_train_val(valset, val_split=0.1)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data/cifar/', train=False, download=True, transform=transform_test)\n",
    "\n",
    "    d_input = 3 if not args.grayscale else 1\n",
    "    d_output = 10\n",
    "\n",
    "elif args.dataset == 'mnist':\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.view(1, 784).t())\n",
    "    ])\n",
    "    transform_train = transform_test = transform\n",
    "\n",
    "    trainset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainset, _ = split_train_val(trainset, val_split=0.1)\n",
    "\n",
    "    valset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform_test)\n",
    "    _, valset = split_train_val(valset, val_split=0.1)\n",
    "\n",
    "    testset = torchvision.datasets.MNIST(\n",
    "        root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "    d_input = 1\n",
    "    d_output = 10\n",
    "else: raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 3]) tensor([4, 5, 8, 4, 3, 9, 8, 6, 9, 6, 4, 2, 8, 5, 5, 3, 1, 1, 7, 5, 8, 3, 2, 3,\n",
      "        9, 6, 2, 8, 1, 8, 9, 8, 0, 4, 8, 8, 2, 4, 6, 0, 5, 4, 9, 6, 5, 0, 5, 0,\n",
      "        5, 7, 0, 6, 5, 9, 0, 0, 6, 3, 7, 0, 4, 8, 7, 4])\n"
     ]
    }
   ],
   "source": [
    "# Taking a single batch of the images\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.size(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.dropout.Dropout1d'>\n"
     ]
    }
   ],
   "source": [
    "# Dropout broke in PyTorch 1.11\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) == (1, 11):\n",
    "    print(\"WARNING: Dropout is bugged in PyTorch 1.11. Results may be worse.\")\n",
    "    dropout_fn = nn.Dropout\n",
    "if tuple(map(int, torch.__version__.split('.')[:2])) >= (1, 12):\n",
    "    dropout_fn = nn.Dropout1d\n",
    "else:\n",
    "    dropout_fn = nn.Dropout2d\n",
    "print(dropout_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output=10,\n",
    "        d_model=256,\n",
    "        n_layers=2,\n",
    "        dropout=0.2,\n",
    "        prenorm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder (d_input = 1 for grayscale and 3 for RGB) (like embedding layer)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        self.FFNs = nn.ModuleList()\n",
    "\n",
    "\n",
    "        for _ in range(n_layers):\n",
    "            self.layers.append(\n",
    "                RNN(d_input = args.d_model, d_model = args.d_model, cell = 'rnn', return_output=True, transposed=False, dropout=0.0)\n",
    "                # nn.RNN(d_model, d_model, nonlinearity = \"relu\")\n",
    "                # S4D(d_model, dropout=dropout, transposed=False, lr=min(1e-7, args.lr))\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(dropout_fn(dropout))\n",
    "            self.FFNs.append(nn.Sequential(nn.Linear(d_model, d_model*2), nn.GLU())                     \n",
    "                                 )\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "        for layer, norm, dropout, FFN in zip(self.layers, self.norms, self.dropouts, self.FFNs):\n",
    "            # Each iteration of this loop will map (B, L, d_model) -> (B, L, d_model)\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z)\n",
    "\n",
    "            # Apply recurrence: we ignore the state input and output\n",
    "            # z, _ = layer(z)\n",
    "\n",
    "            z, _ = layer(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "            \n",
    "            # MLP +GLP\n",
    "            z = FFN(z)\n",
    "\n",
    "            z = dropout(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "\n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "model = Model(\n",
    "    d_input=d_input,\n",
    "    d_output=d_output,\n",
    "    d_model=args.d_model,\n",
    "    n_layers=args.n_layers,\n",
    "    dropout=args.dropout,\n",
    "    prenorm=args.prenorm,\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "if device == 'cuda':\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (encoder): Linear(in_features=3, out_features=128, bias=True)\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x RNN(\n",
      "      (cell): RNNCell(\n",
      "        (W_hx): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (activate): Tanh()\n",
      "        (W_hh): Linear(in_features=128, out_features=128, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-1): 2 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (dropouts): ModuleList(\n",
      "    (0-1): 2 x Dropout1d(p=0.1, inplace=False)\n",
      "  )\n",
      "  (FFNs): ModuleList(\n",
      "    (0-1): 2 x Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): GLU(dim=-1)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133898"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model)\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer group 0 | 20 tensors\n"
     ]
    }
   ],
   "source": [
    "## for S4, S4D\n",
    "\n",
    "def setup_optimizer(model, lr, weight_decay, epochs):\n",
    "    \"\"\"\n",
    "    S4 requires a specific optimizer setup.\n",
    "    The S4 layer (A, B, C, dt) parameters typically\n",
    "    require a smaller learning rate (typically 0.001), with no weight decay.\n",
    "    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)\n",
    "    and weight decay (if desired).\n",
    "    \"\"\"\n",
    "\n",
    "    # All parameters in the model\n",
    "    all_parameters = list(model.parameters())\n",
    "\n",
    "    # General parameters don't contain the special _optim key\n",
    "    params = [p for p in all_parameters if not hasattr(p, \"_optim\")]\n",
    "\n",
    "    # Create an optimizer with the general parameters\n",
    "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Add parameters with special hyperparameters\n",
    "    hps = [getattr(p, \"_optim\") for p in all_parameters if hasattr(p, \"_optim\")]\n",
    "        # e.g., p could be {'weight_decay': 0.0, 'lr': 1e-07}\n",
    "    hps = [\n",
    "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
    "    ]  # Unique dicts \n",
    "    \n",
    "    \n",
    "    for hp in hps: \n",
    "        params = [p for p in all_parameters if getattr(p, \"_optim\", None) == hp] ## select parameter matrices that have \"_optim\" and assign \"_optim = None\" to matrices that do not have\n",
    "        optimizer.add_param_group(\n",
    "            {\"params\": params, **hp} ## <**hp> referes to hyperparameters e.g., {'weight_decay': 0.0}\n",
    "        )\n",
    "\n",
    "    # Create a lr scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "    ''' Print optimizer info '''\n",
    "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
    "    \n",
    "    \n",
    "    for i, g in enumerate(optimizer.param_groups):\n",
    "        group_hps = {k: g.get(k, None) for k in keys}\n",
    "        print(' | '.join([\n",
    "            f\"Optimizer group {i}\",\n",
    "            f\"{len(g['params'])} tensors\",\n",
    "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "optimizer, scheduler = setup_optimizer(\n",
    "    model, lr=args.lr, weight_decay=args.weight_decay, epochs=args.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "### For our implmentation\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay= args.weight_decay)\n",
    "scheduler = CosineWarmup(optimizer, T_max = args.epochs, eta_min= 1e-7, warmup_step= int(args.epochs * 0.1) + 1) \n",
    "print(int(args.epochs * 0.1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.05, 'amsgrad': False, 'foreach': None, 'maximize': False, 'capturable': False, 'differentiable': False, 'fused': None, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict | ## parameter here seems like the index of the parmeter matrics \n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process (train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Everything after this point is standard PyTorch training!\n",
    "###############################################################################\n",
    "\n",
    "# Training\n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(trainloader))\n",
    "    print_every = 50\n",
    "    for batch_idx, (inputs, targets) in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if (batch_idx % print_every) == 0:\n",
    "            print(f\"Batch: {batch_idx}, Avg: {train_loss/(batch_idx+1)}\")\n",
    "        pbar.set_description(\n",
    "            'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "            (batch_idx, len(trainloader), train_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "        )\n",
    "\n",
    "\n",
    "def eval(epoch, dataloader, checkpoint=False):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(dataloader))\n",
    "        for batch_idx, (inputs, targets) in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "            pbar.set_description(\n",
    "                'Batch Idx: (%d/%d) | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "                (batch_idx, len(dataloader), eval_loss/(batch_idx+1), 100.*correct/total, correct, total)\n",
    "            )\n",
    "\n",
    "    # Save checkpoint.\n",
    "    if checkpoint:\n",
    "        acc = 100.*correct/total\n",
    "        if acc > best_acc:\n",
    "            state = {\n",
    "                'model': model.state_dict(),\n",
    "                'acc': acc,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "            if not os.path.isdir('checkpoint'):\n",
    "                os.mkdir('checkpoint')\n",
    "            torch.save(state, './checkpoint/ckpt.pth')\n",
    "            best_acc = acc\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 2.298004150390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 2.086724566478355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 2.057391896106229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 2.0309115885109303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 2.016208737643797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 2.0009899733076058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.9892766257853207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.975150657175613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.9663986797047375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.9544992010767868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.9449558741080308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.937387930719476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.9330700086476205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.926252675679056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.921979105591604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.922 | Acc: 28.640% (12888/45000): : 704it [22:03,  1.88s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.824 | Acc: 32.640% (1632/5000): : 79it [00:52,  1.51it/s]\n",
      "Epoch: 1 | Val acc: 32.640:  10%|█         | 1/10 [22:55<3:26:19, 1375.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.8721773624420166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.8599746741500556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.802751077283727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.8038773828784362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.8010317419298845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.7994761367243124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.7922027808091172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.7875041302792367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.7844640524904627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.7814418119760416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.7757178461718226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.7701020251601232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.7645734120129348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.758605768420546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.7508270575554667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.751 | Acc: 36.529% (16438/45000): : 704it [21:56,  1.87s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.685 | Acc: 40.400% (2020/5000): : 79it [00:55,  1.43it/s]\n",
      "Epoch: 2 | Val acc: 40.400:  20%|██        | 2/10 [45:46<3:03:04, 1373.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.7080577611923218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.6902075515073889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.6698996572211238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.6569338839575154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.65300056768294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.6494339234325515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.6600929059063478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.668319285764993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.6716786920281121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.6735141081714842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.6689388999444044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.6663048875310245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.6594256710093747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.656609974881654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.65251731855553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.653 | Acc: 41.360% (18612/45000): : 704it [21:52,  1.86s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.608 | Acc: 42.160% (2108/5000): : 79it [00:51,  1.53it/s]\n",
      "Epoch: 3 | Val acc: 42.160:  30%|███       | 3/10 [1:08:30<2:39:41, 1368.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.5215574502944946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.5918174491209143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.5881250660018165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.580806410075813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.5809063502212068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.5760601250773882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.5781035098522604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.5783035761950024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.578275391883089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.5747348337110025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.574222963727163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.5733485957455504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.5679396513892887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.5692814207663002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.5690519020662839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.568 | Acc: 44.624% (20081/45000): : 704it [1:11:45,  6.12s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.573 | Acc: 44.140% (2207/5000): : 79it [00:52,  1.52it/s]\n",
      "Epoch: 4 | Val acc: 44.140:  40%|████      | 4/10 [2:21:07<4:14:51, 2548.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.608256459236145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.50482954230963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.5044438532083342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.5067985326249078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.5069933441740957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.5166791544492502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.5222617150145115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.5265727179002897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.5221880329517354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.5206320259364905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.5201987070951632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.5203881153394003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.5187464424853714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.5192422121534332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.5184245060241852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.518 | Acc: 46.389% (20875/45000): : 704it [21:39,  1.85s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.547 | Acc: 44.660% (2233/5000): : 79it [00:53,  1.48it/s]\n",
      "Epoch: 5 | Val acc: 44.660:  50%|█████     | 5/10 [2:43:40<2:56:26, 2117.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.4050382375717163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.491633361461116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.4879884188718135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.4843499163128682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.481457106509612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.4847005676938243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.486024959142818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.4872781259042245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.4871612154040252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.484542067722312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.4824448571709579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.478610132220869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.4788036638012345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.4782142100795623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.4778676235386716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.478 | Acc: 48.062% (21628/45000): : 704it [21:37,  1.84s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.496 | Acc: 46.440% (2322/5000): : 79it [00:51,  1.53it/s]\n",
      "Epoch: 6 | Val acc: 46.440:  60%|██████    | 6/10 [3:06:09<2:03:45, 1856.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.3629142045974731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.4668405757230871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.4601059302245036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.4465318302445065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.447788856515837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.4530785496966296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.449582157736997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.4473677190959964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.4494663908000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.4475076293733855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.4456111004728518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.446248950196697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.447979275478103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.4463443605947421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.4462058659797048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.446 | Acc: 49.531% (22289/45000): : 704it [8:36:18, 44.00s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.491 | Acc: 47.080% (2354/5000): : 79it [00:51,  1.53it/s]\n",
      "Epoch: 7 | Val acc: 47.080:  70%|███████   | 7/10 [11:43:20<9:29:42, 11394.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.476455807685852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.442802209480136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.4263146041643502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.4287957481990587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.417360781437129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.4145674620016637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.4138910493185355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.4167415603273614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.4157315608569214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.4137103446571366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.4167143063630887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.417726729396467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.4185057590884496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.4189744951538226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.4167527106621125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.417 | Acc: 50.569% (22756/45000): : 704it [21:46,  1.86s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.446 | Acc: 49.020% (2451/5000): : 79it [00:51,  1.52it/s]\n",
      "Epoch: 8 | Val acc: 49.020:  80%|████████  | 8/10 [12:05:58<4:33:18, 8199.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.3239713907241821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.3824400165501762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.3896823962136071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.3891515791021436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.3856340317583795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.3811477301605195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.3813024143443948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.3818576374964158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.3833008783119278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.3870755871489413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.3894774734141109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.3880858199566115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.3879033889429344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.39056781442484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.3905285206568905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.390 | Acc: 51.789% (23305/45000): : 704it [21:39,  1.85s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.412 | Acc: 49.620% (2481/5000): : 79it [00:52,  1.51it/s]\n",
      "Epoch: 9 | Val acc: 49.620:  90%|█████████ | 9/10 [12:28:30<1:40:58, 6058.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Avg: 1.4281963109970093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Avg: 1.3799313447054695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Avg: 1.3666988245331415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Avg: 1.3611986321329281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 200, Avg: 1.3737354320080126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 250, Avg: 1.3807935956939759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 300, Avg: 1.3766217580269342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 350, Avg: 1.380200047099013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 400, Avg: 1.3823961539756033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 450, Avg: 1.380147173240814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 500, Avg: 1.3776853660385528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 550, Avg: 1.3772931168170244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 600, Avg: 1.3776404815981669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 650, Avg: 1.3781920896697155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 700, Avg: 1.377910297539367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (703/704) | Loss: 1.378 | Acc: 52.253% (23514/45000): : 704it [21:49,  1.86s/it]\n",
      "Batch Idx: (78/79) | Loss: 1.409 | Acc: 49.760% (2488/5000): : 79it [00:51,  1.53it/s]\n",
      "Epoch: 9 | Val acc: 49.620: 100%|██████████| 10/10 [12:51:12<00:00, 4627.21s/it] \n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(start_epoch, args.epochs))\n",
    "for epoch in pbar:\n",
    "    if epoch == 0:\n",
    "        pbar.set_description('Epoch: %d' % (epoch))\n",
    "    else:\n",
    "        pbar.set_description('Epoch: %d | Val acc: %1.3f' % (epoch, val_acc))\n",
    "    train()\n",
    "    val_acc = eval(epoch, valloader, checkpoint=True)\n",
    "    scheduler.step()\n",
    "    # print(f\"Epoch {epoch} learning rate: {scheduler.get_last_lr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  xavier_uniform_ initlization +  with tanh + 1) with bias + 2) without lr schedule + 3) other hyper parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Idx: (156/157) | Loss: 1.423 | Acc: 50.150% (5015/10000): : 157it [01:44,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "eval(epoch, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
