# @package _global_
defaults:
  - /pipeline: wt2
  - /model: s4
  - override /model/layer: rnn
  - override /scheduler: cosine_warmup

# Dataset
dataset:
  test_split: True
loader:
  batch_size: 50
  l_max: 1024
  n_context: 1
  eval:
    batch_size: null
    l_max: null

task:
  div_val: 1
  dropemb: 0.25
  dropsoft: 0.25

# Model
model:
  dropout: 0.25
  tie_dropout: false
  n_layers: 6
  d_model: 384 
  prenorm: False
  transposed: False
  norm: batch #defaul = layer
  pool: null
  layer:
    cell:
      d_input: 384
      lr: 7.5e-5
      hidden_activation: identity
  track_norms: false

# Optimizer (adamw)
optimizer:
  lr: 3e-4
  weight_decay: 0.1

# Scheduler (cosine)
trainer:
  max_epochs: 200
  # track_grad_norm: 2
  # gradient_clip_val: 0.25

scheduler:
  num_warmup_steps: 976
  num_training_steps: 9760

train:
  seed: 1111
