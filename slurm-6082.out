CONFIG
├── train
│   └── seed: 2222                                                              
│       name: null                                                              
│       interval: step                                                          
│       monitor: val/accuracy                                                   
│       mode: max                                                               
│       ema: 0.0                                                                
│       test: false                                                             
│       debug: false                                                            
│       ignore_warnings: false                                                  
│       state:                                                                  
│         mode: null                                                            
│         n_context: 0                                                          
│         n_context_eval: 0                                                     
│       ckpt: null                                                              
│       disable_dataset: false                                                  
│       validate_at_start: false                                                
│       pretrained_model_path: null                                             
│       pretrained_model_strict_load: true                                      
│       pretrained_model_state_hook:                                            
│         _name_: null                                                          
│       post_init_hook:                                                         
│         _name_: null                                                          
│       layer_decay:                                                            
│         _name_: null                                                          
│         decay: 0.7                                                            
│                                                                               
├── tolerance
│   └── logdir: ./resume                                                        
│       id: null                                                                
│                                                                               
├── wandb
│   └── project: TNLM                                                           
│       group: ''                                                               
│       job_type: training                                                      
│       mode: online                                                            
│       save_dir: .                                                             
│       id: null                                                                
│       name: rnn-lin-mnist-pla                                                 
│                                                                               
├── trainer
│   └── accelerator: gpu                                                        
│       strategy: null                                                          
│       devices: 1                                                              
│       accumulate_grad_batches: 1                                              
│       max_epochs: 100                                                         
│       gradient_clip_val: 0.25                                                 
│       log_every_n_steps: 10                                                   
│       limit_train_batches: 1.0                                                
│       limit_val_batches: 1.0                                                  
│       enable_model_summary: false                                             
│       track_grad_norm: 2                                                      
│       gradient_clip_algorithm: norm                                           
│                                                                               
├── loader
│   └── batch_size: 50                                                          
│       num_workers: 4                                                          
│       pin_memory: true                                                        
│       drop_last: true                                                         
│                                                                               
├── dataset
│   └── _name_: mnist                                                           
│       permute: true                                                           
│       val_split: 0.1                                                          
│       seed: 42                                                                
│                                                                               
├── task
│   └── _name_: base                                                            
│       loss: cross_entropy                                                     
│       metrics:                                                                
│       - accuracy                                                              
│       torchmetrics: null                                                      
│                                                                               
├── optimizer
│   └── _name_: sgd                                                             
│       lr: 7.5e-05                                                             
│       momentum: 0.0                                                           
│       weight_decay: 0.0                                                       
│                                                                               
├── scheduler
│   └── _name_: cosine_warmup                                                   
│       num_warmup_steps: 1080                                                  
│       num_training_steps: 108000                                              
│                                                                               
├── encoder
│   └── linear                                                                  
├── decoder
│   └── _name_: sequence                                                        
│       mode: pool                                                              
│                                                                               
├── model
│   └── layer:                                                                  
│         cell:                                                                 
│           _name_: rnn                                                         
│           hidden_activation: identity                                         
│           orthogonal: false                                                   
│           d_input: 384                                                        
│           lr: 0.0003                                                          
│         _name_: rnn                                                           
│         return_output: true                                                   
│       _name_: model                                                           
│       prenorm: false                                                          
│       transposed: false                                                       
│       n_layers: 1                                                             
│       d_model: 384                                                            
│       bidirectional: false                                                    
│       residual: R                                                             
│       pool: null                                                              
│       norm: batch                                                             
│       dropout: 0.1                                                            
│       tie_dropout: false                                                      
│       track_norms: true                                                       
│       encoder: null                                                           
│       decoder: null                                                           
│                                                                               
└── callbacks
    └── learning_rate_monitor:                                                  
          logging_interval: step                                                
        timer:                                                                  
          step: true                                                            
          inter_step: false                                                     
          epoch: true                                                           
          val: true                                                             
        params:                                                                 
          total: true                                                           
          trainable: true                                                       
          fixed: true                                                           
        model_checkpoint:                                                       
          monitor: val/accuracy                                                 
          mode: max                                                             
          save_top_k: 1                                                         
          save_last: true                                                       
          dirpath: checkpoints/                                                 
          filename: val/accuracy                                                
          auto_insert_metric_name: false                                        
          verbose: true                                                         
        early_stopping:                                                         
          monitor: val/accuracy                                                 
          mode: max                                                             
          patience: 20                                                          
          min_delta: 0                                                          
        rich_model_summary:                                                     
          max_depth: 1                                                          
        rich_progress_bar:                                                      
          refresh_rate: 1                                                       
          leave: true                                                           
                                                                                
[rank: 0] Global seed set to 2222
wandb: Currently logged in as: yuqinzhou. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in ./wandb/run-20230623_125329-1t33k7qd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rnn-lin-mnist-pla
wandb: ⭐️ View project at https://wandb.ai/yuqinzhou/TNLM
wandb: 🚀 View run at https://wandb.ai/yuqinzhou/TNLM/runs/1t33k7qd
[2023-06-23 12:53:34,858][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.LearningRateMonitor>
[2023-06-23 12:53:34,859][__main__][INFO] - Instantiating callback <src.callbacks.timer.Timer>
[2023-06-23 12:53:34,864][__main__][INFO] - Instantiating callback <src.callbacks.params.ParamsLog>
[2023-06-23 12:53:34,865][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2023-06-23 12:53:34,873][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.EarlyStopping>
[2023-06-23 12:53:34,874][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2023-06-23 12:53:34,874][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
NOTE: no dropout inside recurrent cell
SequenceModel(
  (drop): Identity()
  (layers): ModuleList(
    (0): SequenceResidualBlock(
      (layer): RNN(
        (cell): RNNCell(
          (W_hx): Linear(in_features=384, out_features=384, bias=False)
          (activate): Identity()
          (W_hh): Linear(in_features=384, out_features=384, bias=False)
        )
      )
      (residual): Residual()
      (norm): Normalization(
        (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (drop): Dropout(p=0.1, inplace=False)
      (output_linear): Sequential(
        (0): Conv1d(384, 768, kernel_size=(1,), stride=(1,))
        (1): GLU(dim=-2)
      )
      (drop_path): Identity()
    )
  )
  (norm): Identity()
)
NOTE: no dropout inside recurrent cell
Hyperparameter groups [{'weight_decay': 0.0, 'lr': 0.0003}]
[2023-06-23 12:53:37,071][__main__][INFO] - Optimizer group 0 | 8 tensors | lr 7.5e-05 | weight_decay 0.0
[2023-06-23 12:53:37,071][__main__][INFO] - Optimizer group 1 | 2 tensors | lr 0.0003 | weight_decay 0.0
┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name    ┃ Type            ┃ Params ┃
┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model   │ SequenceModel   │  591 K │
│ 1 │ encoder │ Linear          │    768 │
│ 2 │ decoder │ SequenceDecoder │  3.9 K │
└───┴─────────┴─────────────────┴────────┘
Trainable params: 595 K                                                         
Non-trainable params: 0                                                         
Total params: 595 K                                                             
Total estimated model params size (MB): 2                                       
SLURM auto-requeueing enabled. Setting signal handlers.
[2023-06-23 12:53:37,090][__main__][INFO] - Loaded 'val' dataloader:         6000 examples |    120 steps
[2023-06-23 12:53:37,090][__main__][INFO] - Loaded 'test' dataloader:       10000 examples |    200 steps
[2023-06-23 12:53:39,205][__main__][INFO] - Loaded 'train' dataloader:      54000 examples |   1080 steps
Epoch 0, global step 1080: 'val/accuracy' reached 0.15100 (best 0.15100), saving model to '/home/qvk729/Master_thesis/outputs/2023-06-23/12-53-27-325631/checkpoints/val/accuracy.ckpt' as top 1
Epoch 0/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:04 •       13.35it/s loss: 2.3 v_num: 
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.151 val/loss:  
                                                               2.303            
                                                               test/accuracy:   
                                                               0.152 test/loss: 
                                                               2.303            
                                                               train/accuracy:  
                                                               0.104 train/loss:
                                                               2.304            
Epoch 1, global step 2160: 'val/accuracy' was not in top 1
Epoch 1/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:04 •       13.21it/s loss: 2.24 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.105 val/loss:  
                                                               2.273            
                                                               test/accuracy:   
                                                               0.103 test/loss: 
                                                               2.283            
                                                               train/accuracy:  
                                                               0.143 train/loss:
                                                               2.28             
Epoch 2, global step 3240: 'val/accuracy' was not in top 1
Epoch 2/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:04 •       13.19it/s loss: 2.23 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.143 val/loss:  
                                                               2.226            
                                                               test/accuracy:   
                                                               0.141 test/loss: 
                                                               2.231            
                                                               train/accuracy:  
                                                               0.145 train/loss:
                                                               2.224            
Epoch 3, global step 4320: 'val/accuracy' reached 0.15233 (best 0.15233), saving model to '/home/qvk729/Master_thesis/outputs/2023-06-23/12-53-27-325631/checkpoints/val/accuracy.ckpt' as top 1
Epoch 3/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:02 •       13.34it/s loss: 2.23 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.152 val/loss:  
                                                               2.21             
                                                               test/accuracy:   
                                                               0.147 test/loss: 
                                                               2.217            
                                                               train/accuracy:  
                                                               0.145 train/loss:
                                                               2.218            
Epoch 4, global step 5400: 'val/accuracy' was not in top 1
Epoch 4/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:02 •       13.24it/s loss: 2.19 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.148 val/loss:  
                                                               2.201            
                                                               test/accuracy:   
                                                               0.147 test/loss: 
                                                               2.208            
                                                               train/accuracy:  
                                                               0.144 train/loss:
                                                               2.213            
Epoch 5, global step 6480: 'val/accuracy' was not in top 1
Epoch 5/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:06 •       12.84it/s loss: 2.23 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.149 val/loss:  
                                                               2.276            
                                                               test/accuracy:   
                                                               0.14 test/loss:  
                                                               2.278            
                                                               train/accuracy:  
                                                               0.144 train/loss:
                                                               2.21             
Epoch 6, global step 7560: 'val/accuracy' reached 0.20133 (best 0.20133), saving model to '/home/qvk729/Master_thesis/outputs/2023-06-23/12-53-27-325631/checkpoints/val/accuracy.ckpt' as top 1
Epoch 6/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:12 •       13.00it/s loss: 2.19 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.201 val/loss:  
                                                               2.184            
                                                               test/accuracy:   
                                                               0.198 test/loss: 
                                                               2.189            
                                                               train/accuracy:  
                                                               0.194 train/loss:
                                                               2.202            
Epoch 7, global step 8640: 'val/accuracy' reached 0.21500 (best 0.21500), saving model to '/home/qvk729/Master_thesis/outputs/2023-06-23/12-53-27-325631/checkpoints/val/accuracy.ckpt' as top 1
Epoch 7/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:11 •       12.95it/s loss: 2.18 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.215 val/loss:  
                                                               2.188            
                                                               test/accuracy:   
                                                               0.214 test/loss: 
                                                               2.192            
                                                               train/accuracy:  
                                                               0.206 train/loss:
                                                               2.196            
Epoch 8, global step 9720: 'val/accuracy' was not in top 1
Epoch 8/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:09 •       13.05it/s loss: 2.2 v_num: 
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.189 val/loss:  
                                                               2.222            
                                                               test/accuracy:   
                                                               0.191 test/loss: 
                                                               2.226            
                                                               train/accuracy:  
                                                               0.205 train/loss:
                                                               2.192            
Epoch 9, global step 10800: 'val/accuracy' was not in top 1
Epoch 9/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:09 •       13.08it/s loss: 2.18 v_num:
                                     0:00:00                   k7qd             
                                                               val/accuracy:    
                                                               0.209 val/loss:  
                                                               2.207            
                                                               test/accuracy:   
                                                               0.212 test/loss: 
                                                               2.212            
                                                               train/accuracy:  
                                                               0.208 train/loss:
                                                               2.19             
Epoch 10, global step 11880: 'val/accuracy' was not in top 1
Epoch 10/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:09 •       12.90it/s loss: 2.18      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.203 val/loss: 
                                                                2.176           
                                                                test/accuracy:  
                                                                0.204 test/loss:
                                                                2.18            
                                                                train/accuracy: 
                                                                0.208           
                                                                train/loss:     
                                                                2.186           
Epoch 11, global step 12960: 'val/accuracy' was not in top 1
Epoch 11/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:10 •       13.13it/s loss: 2.18      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.205 val/loss: 
                                                                2.182           
                                                                test/accuracy:  
                                                                0.207 test/loss:
                                                                2.186           
                                                                train/accuracy: 
                                                                0.205           
                                                                train/loss:     
                                                                2.184           
Epoch 12, global step 14040: 'val/accuracy' was not in top 1
Epoch 12/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:11 •       12.94it/s loss: 2.18      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.194 val/loss: 
                                                                2.225           
                                                                test/accuracy:  
                                                                0.198 test/loss:
                                                                2.229           
                                                                train/accuracy: 
                                                                0.205           
                                                                train/loss:     
                                                                2.182           
Epoch 13, global step 15120: 'val/accuracy' was not in top 1
Epoch 13/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:08 •       13.12it/s loss: 2.2 v_num:
                                      0:00:00                   k7qd            
                                                                val/accuracy:   
                                                                0.207 val/loss: 
                                                                2.208           
                                                                test/accuracy:  
                                                                0.206 test/loss:
                                                                2.212           
                                                                train/accuracy: 
                                                                0.206           
                                                                train/loss: 2.18
Epoch 14, global step 16200: 'val/accuracy' was not in top 1
Epoch 14/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:11 •       12.90it/s loss: 2.18      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.203 val/loss: 
                                                                2.181           
                                                                test/accuracy:  
                                                                0.206 test/loss:
                                                                2.185           
                                                                train/accuracy: 
                                                                0.204           
                                                                train/loss:     
                                                                2.178           
Epoch 15, global step 17280: 'val/accuracy' was not in top 1
Epoch 15/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:12 •       13.00it/s loss: 2.17      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.203 val/loss: 
                                                                2.181           
                                                                test/accuracy:  
                                                                0.204 test/loss:
                                                                2.184           
                                                                train/accuracy: 
                                                                0.203           
                                                                train/loss:     
                                                                2.175           
Epoch 16, global step 18360: 'val/accuracy' was not in top 1
Epoch 16/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:12 •       12.85it/s loss: 2.17      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.183 val/loss: 
                                                                2.193           
                                                                test/accuracy:  
                                                                0.181 test/loss:
                                                                2.195           
                                                                train/accuracy: 
                                                                0.201           
                                                                train/loss:     
                                                                2.173           
Epoch 17, global step 19440: 'val/accuracy' was not in top 1
Epoch 17/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:11 •       12.86it/s loss: 2.16      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.187 val/loss: 
                                                                2.163           
                                                                test/accuracy:  
                                                                0.184 test/loss:
                                                                2.165           
                                                                train/accuracy: 
                                                                0.202           
                                                                train/loss:     
                                                                2.172           
Epoch 18, global step 20520: 'val/accuracy' was not in top 1
Epoch 18/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:08 •       13.10it/s loss: 2.16      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.199 val/loss: 
                                                                2.216           
                                                                test/accuracy:  
                                                                0.203 test/loss:
                                                                2.22            
                                                                train/accuracy: 
                                                                0.202           
                                                                train/loss:     
                                                                2.171           
Epoch 19, global step 21600: 'val/accuracy' was not in top 1
Epoch 19/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:09 •       13.00it/s loss: 2.15      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.2 val/loss:   
                                                                2.167           
                                                                test/accuracy:  
                                                                0.202 test/loss:
                                                                2.17            
                                                                train/accuracy: 
                                                                0.2 train/loss: 
                                                                2.166           
Epoch 20, global step 22680: 'val/accuracy' was not in top 1
Epoch 20/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:11 •       13.08it/s loss: 2.17      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.2 val/loss:   
                                                                2.162           
                                                                test/accuracy:  
                                                                0.203 test/loss:
                                                                2.165           
                                                                train/accuracy: 
                                                                0.2 train/loss: 
                                                                2.162           
Epoch 21, global step 23760: 'val/accuracy' was not in top 1
Epoch 21/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:07 •       13.15it/s loss: 2.17      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.199 val/loss: 
                                                                2.167           
                                                                test/accuracy:  
                                                                0.201 test/loss:
                                                                2.17            
                                                                train/accuracy: 
                                                                0.2 train/loss: 
                                                                2.16            
Epoch 22, global step 24840: 'val/accuracy' was not in top 1
Epoch 22/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:09 •       12.96it/s loss: 2.12      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.202 val/loss: 
                                                                2.18            
                                                                test/accuracy:  
                                                                0.204 test/loss:
                                                                2.184           
                                                                train/accuracy: 
                                                                0.2 train/loss: 
                                                                2.16            
Epoch 23, global step 25920: 'val/accuracy' was not in top 1
Epoch 23/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:10 •       12.96it/s loss: 2.16      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.202 val/loss: 
                                                                2.187           
                                                                test/accuracy:  
                                                                0.202 test/loss:
                                                                2.19            
                                                                train/accuracy: 
                                                                0.199           
                                                                train/loss:     
                                                                2.158           
Epoch 24, global step 27000: 'val/accuracy' was not in top 1
Epoch 24/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:09 •       13.06it/s loss: 2.18      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.194 val/loss: 
                                                                2.146           
                                                                test/accuracy:  
                                                                0.194 test/loss:
                                                                2.148           
                                                                train/accuracy: 
                                                                0.2 train/loss: 
                                                                2.157           
Epoch 25, global step 28080: 'val/accuracy' was not in top 1
Epoch 25/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:10 •       13.06it/s loss: 2.16      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.2 val/loss:   
                                                                2.178           
                                                                test/accuracy:  
                                                                0.203 test/loss:
                                                                2.181           
                                                                train/accuracy: 
                                                                0.199           
                                                                train/loss:     
                                                                2.155           
Epoch 26, global step 29160: 'val/accuracy' was not in top 1
Epoch 26/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:08 •       13.18it/s loss: 2.17      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.19 val/loss:  
                                                                2.141           
                                                                test/accuracy:  
                                                                0.189 test/loss:
                                                                2.143           
                                                                train/accuracy: 
                                                                0.199           
                                                                train/loss:     
                                                                2.155           
Epoch 27, global step 30240: 'val/accuracy' was not in top 1
Epoch 27/99 ━━━━━━━━━━━━━━━ 1400/1400 0:03:10 •       12.97it/s loss: 2.15      
                                      0:00:00                   v_num: k7qd     
                                                                val/accuracy:   
                                                                0.193 val/loss: 
                                                                2.139           
                                                                test/accuracy:  
                                                                0.193 test/loss:
                                                                2.141           
                                                                train/accuracy: 
                                                                0.199           
                                                                train/loss:     
                                                                2.153           
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                                     epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:       grad_2.0_norm/decoder.0.output_transform.bias_epoch ▁▂▂▆▆▇▃▇▅▁▃▇▆▆▆▃▆▇▆▆██▆▅▇█▆▆
wandb:        grad_2.0_norm/decoder.0.output_transform.bias_step ▅▄▅▅▁▂▄▇▅▅▂▅▃▅▆▆▄▃▄▅█▄▃█▇▇▇▃▅▆▇▅▅▅▄▆▅▄█▇
wandb:     grad_2.0_norm/decoder.0.output_transform.weight_epoch ▁▃▇█████████████████████████
wandb:      grad_2.0_norm/decoder.0.output_transform.weight_step ▁▁▂▇▅▆▇▆▄▆▅▅▅▅▅▅▇▇▇▆▅▅▅▅█▇█▅▆▅▅▅▅▅▅▄▇▄▄█
wandb:                        grad_2.0_norm/encoder.0.bias_epoch ▁▃█▇▇▇▆▆▆▆▆▆▆▆▆▅▆▆▅▅▅▅▅▅▅▅▅▅
wandb:                         grad_2.0_norm/encoder.0.bias_step ▁▁▁▁▃▃▃▃▂█▂▄▃▂▁▂▂▁▂▁▅▁▁▂▁▂▁▂▁▁▁▂▁▁▁▁▂▂▁▂
wandb:                      grad_2.0_norm/encoder.0.weight_epoch ▁▆█▅▅▅▄▅▄▄▄▄▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃
wandb:                       grad_2.0_norm/encoder.0.weight_step ▁▁▄▂▃▃▂▃▂▇▁▄▅▂▁▂▃▁▁▂█▁▁▂▂▃▂▁▂▁▁▁▁▁▁▁▄▂▂▃
wandb: grad_2.0_norm/model.layers.0.layer.cell.W_hh.weight_epoch ▁▂▇▆▅▆▇▆▇▇▆▇▇▇▇▆▇▇▇█▇▇▇▇▇▇▆▆
wandb:  grad_2.0_norm/model.layers.0.layer.cell.W_hh.weight_step ▁▁▁▄▃▄▃▃▃█▁▂▃▃▂▂▃▄▂▃▆▂▂▃▄▃▂▃▁▄▂▂▂▁▁▁▁▁▂▄
wandb: grad_2.0_norm/model.layers.0.layer.cell.W_hx.weight_epoch ▁▃█▇▇▇▆▆▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▅▅▅▅▄
wandb:  grad_2.0_norm/model.layers.0.layer.cell.W_hx.weight_step ▁▁▁▁▃▃▃▃▂█▂▄▃▂▁▂▂▁▂▁▅▁▁▂▁▂▁▂▁▁▁▂▁▁▁▁▂▂▁▂
wandb:         grad_2.0_norm/model.layers.0.norm.norm.bias_epoch ▁▂▂▆▇▇▃▇▅▁▄▇▆▆▆▄▆▇▆▆██▆▅▇█▆▆
wandb:          grad_2.0_norm/model.layers.0.norm.norm.bias_step ▆▄▅▅▁▂▄▇▅▆▂▅▃▅▆▆▄▃▅▅█▅▃█▇▇█▄▅▇▇▅▆▅▄▆▅▄██
wandb:       grad_2.0_norm/model.layers.0.norm.norm.weight_epoch ▁▃▇█████████████████████████
wandb:        grad_2.0_norm/model.layers.0.norm.norm.weight_step ▁▁▂▇▅▆▇▆▄▇▅▆▅▅▅▆▇▇█▆▅▆▅▅█▇█▅▆▅▅▅▅▅▅▅▇▅▄█
wandb:                                 grad_2.0_norm_total_epoch ▁▂▇▆▅▆▇▆▇▇▆▇▇▇▇▆▇▇▇█▇▇▇▇▇▇▆▆
wandb:                                  grad_2.0_norm_total_step ▁▁▁▄▃▄▃▃▃█▁▂▃▃▂▂▃▄▂▃▆▂▂▃▄▃▂▃▁▄▂▂▂▁▁▁▁▁▂▄
wandb:                                                    norm/0 ▂▁▅▂▅▁▃▄▃▅▅█▇▄▆▄▆▅▄▆▅▅▄▄▆▇▇▆▂▆▅▆▇▇█▄▂▃▂▂
wandb:                                                    norm/1 ██▅▇█▇▇▇▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▄▄▃▄▃▃▃▁▁▁▂
wandb:                                             test/accuracy ▄▁▃▄▄▃▇█▇█▇█▇▇█▇▆▆▇▇▇▇▇▇▇▇▆▇
wandb:                                                 test/loss █▇▅▄▄▇▃▃▅▄▃▃▅▄▃▃▃▂▄▂▂▂▃▃▁▃▁▁
wandb:                                               timer/epoch ▃▃▃▁▁▄█▇▆▆▆▇▇▅▇██▇▅▆▇▅▆▆▆▇▅▆
wandb:                                                timer/step ▃▄▅▃▆▃▂▁▄▇▃▄▅▆▅▆▇▇▆▆█▇▇▇▆▆▄▃▇▆▄▄▃▆▅▇▅▄▃▆
wandb:                                          timer/validation ▁▇▇█▇▇███████████████████████
wandb:                                            train/accuracy ▁▄▄▄▄▄▇█████████████▇▇▇▇▇▇▇▇
wandb:                                                train/loss █▇▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:                                             trainer/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:                                       trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                                              trainer/loss ██▇▅▅▄▄▅▆▁▅▃▄▅▅▅▆▂▂▆▄▃▄▅▅▆▃▃▄▁▅▂▆▅▅▅▁▅▃▁
wandb:                                            trainer/lr/pg1 ▁▇████████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆
wandb:                                            trainer/lr/pg2 ▁▇████████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆
wandb:                                              val/accuracy ▄▁▃▄▄▄▇█▆█▇▇▇█▇▇▆▆▇▇▇▇▇▇▇▇▆▇
wandb:                                                  val/loss █▇▅▄▄▇▃▃▅▄▃▃▅▄▃▃▃▂▄▂▂▂▃▃▁▃▁▁
wandb: 
wandb: Run summary:
wandb:                                                     epoch 27
wandb:       grad_2.0_norm/decoder.0.output_transform.bias_epoch 0.1349
wandb:        grad_2.0_norm/decoder.0.output_transform.bias_step 0.1387
wandb:     grad_2.0_norm/decoder.0.output_transform.weight_epoch 2.16096
wandb:      grad_2.0_norm/decoder.0.output_transform.weight_step 1.9469
wandb:                        grad_2.0_norm/encoder.0.bias_epoch 0.07867
wandb:                         grad_2.0_norm/encoder.0.bias_step 0.0478
wandb:                      grad_2.0_norm/encoder.0.weight_epoch 0.01034
wandb:                       grad_2.0_norm/encoder.0.weight_step 0.0019
wandb: grad_2.0_norm/model.layers.0.layer.cell.W_hh.weight_epoch 65.81371
wandb:  grad_2.0_norm/model.layers.0.layer.cell.W_hh.weight_step 31.488
wandb: grad_2.0_norm/model.layers.0.layer.cell.W_hx.weight_epoch 0.88893
wandb:  grad_2.0_norm/model.layers.0.layer.cell.W_hx.weight_step 0.5328
wandb:         grad_2.0_norm/model.layers.0.norm.norm.bias_epoch 0.07812
wandb:          grad_2.0_norm/model.layers.0.norm.norm.bias_step 0.0802
wandb:       grad_2.0_norm/model.layers.0.norm.norm.weight_epoch 0.06442
wandb:        grad_2.0_norm/model.layers.0.norm.norm.weight_step 0.058
wandb:                                 grad_2.0_norm_total_epoch 65.91694
wandb:                                  grad_2.0_norm_total_step 31.5532
wandb:                                                    norm/0 0.37174
wandb:                                                    norm/1 1.0
wandb:                                             test/accuracy 0.1928
wandb:                                                 test/loss 2.14116
wandb:                                               timer/epoch 190.10279
wandb:                                                timer/step 0.14962
wandb:                                          timer/validation 18.94969
wandb:                                            train/accuracy 0.19896
wandb:                                                train/loss 2.1531
wandb:                                             trainer/epoch 27.0
wandb:                                       trainer/global_step 30239
wandb:                                              trainer/loss 2.18045
wandb:                                            trainer/lr/pg1 6e-05
wandb:                                            trainer/lr/pg2 0.00025
wandb:                                              val/accuracy 0.19333
wandb:                                                  val/loss 2.1387
wandb: 
wandb: 🚀 View run rnn-lin-mnist-pla at: https://wandb.ai/yuqinzhou/TNLM/runs/1t33k7qd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230623_125329-1t33k7qd/logs
