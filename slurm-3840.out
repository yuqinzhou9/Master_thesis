CONFIG
‚îú‚îÄ‚îÄ train
‚îÇ   ‚îî‚îÄ‚îÄ seed: 1111                                                              
‚îÇ       name: null                                                              
‚îÇ       interval: step                                                          
‚îÇ       monitor: val/loss                                                       
‚îÇ       mode: min                                                               
‚îÇ       ema: 0.0                                                                
‚îÇ       test: false                                                             
‚îÇ       debug: false                                                            
‚îÇ       ignore_warnings: false                                                  
‚îÇ       state:                                                                  
‚îÇ         mode: null                                                            
‚îÇ         n_context: 0                                                          
‚îÇ         n_context_eval: 0                                                     
‚îÇ       ckpt: null                                                              
‚îÇ       disable_dataset: false                                                  
‚îÇ       validate_at_start: false                                                
‚îÇ       pretrained_model_path: null                                             
‚îÇ       pretrained_model_strict_load: true                                      
‚îÇ       pretrained_model_state_hook:                                            
‚îÇ         _name_: null                                                          
‚îÇ       post_init_hook:                                                         
‚îÇ         _name_: null                                                          
‚îÇ       layer_decay:                                                            
‚îÇ         _name_: null                                                          
‚îÇ         decay: 0.7                                                            
‚îÇ                                                                               
‚îú‚îÄ‚îÄ tolerance
‚îÇ   ‚îî‚îÄ‚îÄ logdir: ./resume                                                        
‚îÇ       id: null                                                                
‚îÇ                                                                               
‚îú‚îÄ‚îÄ wandb
‚îÇ   ‚îî‚îÄ‚îÄ project: TNLM                                                           
‚îÇ       group: ''                                                               
‚îÇ       job_type: training                                                      
‚îÇ       mode: online                                                            
‚îÇ       save_dir: .                                                             
‚îÇ       id: null                                                                
‚îÇ       name: s4-wt2                                                            
‚îÇ                                                                               
‚îú‚îÄ‚îÄ trainer
‚îÇ   ‚îî‚îÄ‚îÄ accelerator: gpu                                                        
‚îÇ       devices: 1                                                              
‚îÇ       accumulate_grad_batches: 1                                              
‚îÇ       max_epochs: 1000                                                        
‚îÇ       gradient_clip_val: null                                                 
‚îÇ       log_every_n_steps: 10                                                   
‚îÇ       precision: 16                                                           
‚îÇ       enable_model_summary: false                                             
‚îÇ       track_grad_norm: -1                                                     
‚îÇ       limit_train_batches: 1.0                                                
‚îÇ       limit_val_batches: 1.0                                                  
‚îÇ       replace_sampler_ddp: false                                              
‚îÇ                                                                               
‚îú‚îÄ‚îÄ loader
‚îÇ   ‚îî‚îÄ‚îÄ batch_first: true                                                       
‚îÇ       batch_size: 1                                                           
‚îÇ       l_max: 512                                                              
‚îÇ       pad_last: false                                                         
‚îÇ       n_context: 1                                                            
‚îÇ       n_epoch_double: 0                                                       
‚îÇ       limit_tokens: 1.0                                                       
‚îÇ       eval:                                                                   
‚îÇ         l_max: null                                                           
‚îÇ         batch_size: null                                                      
‚îÇ                                                                               
‚îú‚îÄ‚îÄ dataset
‚îÇ   ‚îî‚îÄ‚îÄ _name_: wt2                                                             
‚îÇ       data_dir: null                                                          
‚îÇ       bpe: false                                                              
‚îÇ       roll_seed: 42                                                           
‚îÇ       test_split: true                                                        
‚îÇ                                                                               
‚îú‚îÄ‚îÄ optimizer
‚îÇ   ‚îî‚îÄ‚îÄ _name_: adamw                                                           
‚îÇ       lr: 0.0005                                                              
‚îÇ       weight_decay: 0.1                                                       
‚îÇ       betas:                                                                  
‚îÇ       - 0.9                                                                   
‚îÇ       - 0.999                                                                 
‚îÇ                                                                               
‚îú‚îÄ‚îÄ scheduler
‚îÇ   ‚îî‚îÄ‚îÄ _name_: cosine_warmup                                                   
‚îÇ       num_warmup_steps: 1000                                                  
‚îÇ       num_training_steps: 800000                                              
‚îÇ                                                                               
‚îú‚îÄ‚îÄ task
‚îÇ   ‚îî‚îÄ‚îÄ _name_: adaptivelm                                                      
‚îÇ       init_scale: 0.5                                                         
‚îÇ       bias_scale: 1.0                                                         
‚îÇ       div_val: 1                                                              
‚îÇ       cutoffs:                                                                
‚îÇ       - 9997                                                                  
‚îÇ       - 19997                                                                 
‚îÇ       - 29997                                                                 
‚îÇ       tie_weights: true                                                       
‚îÇ       tie_projs:                                                              
‚îÇ       - true                                                                  
‚îÇ       - true                                                                  
‚îÇ       - true                                                                  
‚îÇ       dropemb: 0.1                                                            
‚îÇ       dropsoft: 0.1                                                           
‚îÇ       loss: null                                                              
‚îÇ       metrics:                                                                
‚îÇ       - ppl                                                                   
‚îÇ                                                                               
‚îú‚îÄ‚îÄ encoder
‚îÇ   ‚îî‚îÄ‚îÄ None                                                                    
‚îú‚îÄ‚îÄ decoder
‚îÇ   ‚îî‚îÄ‚îÄ sequence                                                                
‚îú‚îÄ‚îÄ model
‚îÇ   ‚îî‚îÄ‚îÄ layer:                                                                  
‚îÇ       - _name_: s4                                                            
‚îÇ         l_max: 512                                                            
‚îÇ         final_act: glu                                                        
‚îÇ         dropout: 0.1                                                          
‚îÇ         lr: 0.0005                                                            
‚îÇ         n_ssm: 1                                                              
‚îÇ       - _name_: s4                                                            
‚îÇ         l_max: 512                                                            
‚îÇ         final_act: glu                                                        
‚îÇ         dropout: 0.1                                                          
‚îÇ         lr: 0.0005                                                            
‚îÇ         n_ssm: 1                                                              
‚îÇ       - _name_: ffn                                                           
‚îÇ         expand: 4                                                             
‚îÇ         activation: gelu                                                      
‚îÇ         dropout: 0.1                                                          
‚îÇ       _name_: model                                                           
‚îÇ       prenorm: true                                                           
‚îÇ       transposed: false                                                       
‚îÇ       n_layers: 6                                                             
‚îÇ       d_model: 512                                                            
‚îÇ       bidirectional: false                                                    
‚îÇ       residual: R                                                             
‚îÇ       pool:                                                                   
‚îÇ         _name_: pool                                                          
‚îÇ         stride: 1                                                             
‚îÇ         expand: null                                                          
‚îÇ       norm: layer                                                             
‚îÇ       dropout: 0.1                                                            
‚îÇ       tie_dropout: false                                                      
‚îÇ       track_norms: true                                                       
‚îÇ       encoder: null                                                           
‚îÇ       decoder: null                                                           
‚îÇ       dropinp: 0.0                                                            
‚îÇ                                                                               
‚îî‚îÄ‚îÄ callbacks
    ‚îî‚îÄ‚îÄ learning_rate_monitor:                                                  
          logging_interval: step                                                
        timer:                                                                  
          step: true                                                            
          inter_step: false                                                     
          epoch: true                                                           
          val: true                                                             
        params:                                                                 
          total: true                                                           
          trainable: true                                                       
          fixed: true                                                           
        model_checkpoint:                                                       
          monitor: val/loss                                                     
          mode: min                                                             
          save_top_k: 1                                                         
          save_last: true                                                       
          dirpath: checkpoints/                                                 
          filename: val/loss                                                    
          auto_insert_metric_name: false                                        
          verbose: true                                                         
        rich_model_summary:                                                     
          max_depth: 1                                                          
        rich_progress_bar:                                                      
          refresh_rate: 1                                                       
          leave: true                                                           
                                                                                
[rank: 0] Global seed set to 1111
wandb: Currently logged in as: yuqinzhou. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in ./wandb/run-20230715_212221-mt4tyl2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run s4-wt2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yuqinzhou/TNLM
wandb: üöÄ View run at https://wandb.ai/yuqinzhou/TNLM/runs/mt4tyl2h
[2023-07-15 21:22:25,839][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.LearningRateMonitor>
[2023-07-15 21:22:25,840][__main__][INFO] - Instantiating callback <src.callbacks.timer.Timer>
[2023-07-15 21:22:25,843][__main__][INFO] - Instantiating callback <src.callbacks.params.ParamsLog>
[2023-07-15 21:22:25,845][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2023-07-15 21:22:25,846][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2023-07-15 21:22:25,846][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
Using 16bit None Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2023-07-15 21:22:25,883][root][INFO] - Loading cached dataset...
Vocab size: 33278
[2023-07-15 21:22:26,083][src.models.sequence.kernels.ssm][WARNING] - CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.
[2023-07-15 21:22:26,083][src.models.sequence.kernels.ssm][WARNING] - Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.
[2023-07-15 21:22:26,102][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,118][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,164][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,180][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,225][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,242][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,289][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,306][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,357][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,374][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,422][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
[2023-07-15 21:22:26,440][src.models.sequence.kernels.ssm][INFO] - Constructing S4 (H, N, L) = (512, 32, 512)
vocabulary: 33278
SequenceLightningModule(
  (model): SequenceModel(
    (drop): Identity()
    (layers): ModuleList(
      (0): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (1): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (2): SequenceResidualBlock(
        (layer): FFN(
          (ff): Sequential(
            (0): Sequential(
              (0): Linear(in_features=512, out_features=2048, bias=True)
              (1): GELU(approximate=none)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (3): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (4): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (5): SequenceResidualBlock(
        (layer): FFN(
          (ff): Sequential(
            (0): Sequential(
              (0): Linear(in_features=512, out_features=2048, bias=True)
              (1): GELU(approximate=none)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (6): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (7): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (8): SequenceResidualBlock(
        (layer): FFN(
          (ff): Sequential(
            (0): Sequential(
              (0): Linear(in_features=512, out_features=2048, bias=True)
              (1): GELU(approximate=none)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (9): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (10): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (11): SequenceResidualBlock(
        (layer): FFN(
          (ff): Sequential(
            (0): Sequential(
              (0): Linear(in_features=512, out_features=2048, bias=True)
              (1): GELU(approximate=none)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (12): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (13): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (14): SequenceResidualBlock(
        (layer): FFN(
          (ff): Sequential(
            (0): Sequential(
              (0): Linear(in_features=512, out_features=2048, bias=True)
              (1): GELU(approximate=none)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (15): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (16): SequenceResidualBlock(
        (layer): S4Block(
          (layer): FFTConv(
            (activation): GELU(approximate=none)
            (kernel): SSMKernelDPLR()
            (drop): Dropout(p=0.1, inplace=False)
            (drop_kernel): Identity()
          )
          (mult_activation): Identity()
          (drop): Dropout(p=0.1, inplace=False)
          (output_linear): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): GLU(dim=-1)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
      (17): SequenceResidualBlock(
        (layer): FFN(
          (ff): Sequential(
            (0): Sequential(
              (0): Linear(in_features=512, out_features=2048, bias=True)
              (1): GELU(approximate=none)
            )
            (1): Dropout(p=0.1, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (pool): DownAvgPool()
        (drop): Dropout1d(p=0.1, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
    )
    (norm): Normalization(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (encoder): AdaptiveEmbedding(
    (0): AdaptiveEmbedding(
      (drop): Dropout(p=0.1, inplace=False)
      (emb_layers): ModuleList(
        (0): Embedding(33278, 512)
      )
      (emb_projs): ParameterList()
    )
  )
  (decoder): SequenceDecoder(
    (0): SequenceDecoder(
      (output_transform): Identity()
    )
  )
  (loss): ProjectedAdaptiveLogSoftmax(
    (out_layers_biases): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 33278])
    (shared_out_projs): ParameterList()
    (out_projs): OptionalParameterList()
    (drop): Dropout(p=0.1, inplace=False)
  )
  (loss_val): ProjectedAdaptiveLogSoftmax(
    (out_layers_biases): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 33278])
    (shared_out_projs): ParameterList()
    (out_projs): OptionalParameterList()
    (drop): Dropout(p=0.1, inplace=False)
  )
)
[2023-07-15 21:22:26,837][root][INFO] - Loading cached dataset...
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Vocab size: 33278
Hyperparameter groups [{'lr': 0.0005, 'weight_decay': 0.0}]
[2023-07-15 21:22:28,593][__main__][INFO] - Optimizer group 0 | 150 tensors | lr 0.0005 | weight_decay 0.1
[2023-07-15 21:22:28,593][__main__][INFO] - Optimizer group 1 | 60 tensors | lr 0.0005 | weight_decay 0.0
‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ   ‚îÉ Name    ‚îÉ Type                        ‚îÉ Params ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ 0 ‚îÇ model   ‚îÇ SequenceModel               ‚îÇ 28.8 M ‚îÇ
‚îÇ 1 ‚îÇ encoder ‚îÇ AdaptiveEmbedding           ‚îÇ 17.0 M ‚îÇ
‚îÇ 2 ‚îÇ decoder ‚îÇ SequenceDecoder             ‚îÇ      0 ‚îÇ
‚îÇ 3 ‚îÇ loss    ‚îÇ ProjectedAdaptiveLogSoftmax ‚îÇ 34.8 K ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Trainable params: 45.9 M                                                        
Non-trainable params: 0                                                         
Total params: 45.9 M                                                            
Total estimated model params size (MB): 91                                      
SLURM auto-requeueing enabled. Setting signal handlers.
eval loader: {'l_max': 512, 'batch_size': 1, 'batch_first': True, 'pad_last': False, 'n_context': 1, 'n_epoch_double': 0, 'limit_tokens': 1.0}
eval loader: {'l_max': 512, 'batch_size': 1, 'batch_first': True, 'pad_last': False, 'n_context': 1, 'n_epoch_double': 0, 'limit_tokens': 1.0}
[2023-07-15 21:22:28,632][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,475][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,482][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,488][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,495][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,501][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,508][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,514][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,520][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,527][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,533][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
[2023-07-15 21:22:30,539][src.models.sequence.kernels.ssm][INFO] - S4: Initializing kernel to length 512
