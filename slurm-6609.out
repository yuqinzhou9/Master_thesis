CONFIG
├── train
│   └── seed: 1111                                                              
│       name: null                                                              
│       interval: step                                                          
│       monitor: val/loss                                                       
│       mode: min                                                               
│       ema: 0.0                                                                
│       test: false                                                             
│       debug: false                                                            
│       ignore_warnings: false                                                  
│       state:                                                                  
│         mode: null                                                            
│         n_context: 0                                                          
│         n_context_eval: 0                                                     
│       ckpt: null                                                              
│       disable_dataset: false                                                  
│       validate_at_start: false                                                
│       pretrained_model_path: null                                             
│       pretrained_model_strict_load: true                                      
│       pretrained_model_state_hook:                                            
│         _name_: null                                                          
│       post_init_hook:                                                         
│         _name_: null                                                          
│       layer_decay:                                                            
│         _name_: null                                                          
│         decay: 0.7                                                            
│                                                                               
├── tolerance
│   └── logdir: ./resume                                                        
│       id: null                                                                
│                                                                               
├── wandb
│   └── project: TNLM                                                           
│       group: ''                                                               
│       job_type: training                                                      
│       mode: online                                                            
│       save_dir: .                                                             
│       id: null                                                                
│       name: mirnn-lin-wt2                                                     
│                                                                               
├── trainer
│   └── accelerator: gpu                                                        
│       devices: 1                                                              
│       accumulate_grad_batches: 1                                              
│       max_epochs: 200                                                         
│       gradient_clip_val: null                                                 
│       log_every_n_steps: 10                                                   
│       precision: 16                                                           
│       enable_model_summary: false                                             
│       track_grad_norm: -1                                                     
│       limit_train_batches: 1.0                                                
│       limit_val_batches: 1.0                                                  
│       replace_sampler_ddp: false                                              
│                                                                               
├── loader
│   └── batch_first: true                                                       
│       batch_size: 50                                                          
│       l_max: 32                                                               
│       pad_last: false                                                         
│       n_context: 1                                                            
│       n_epoch_double: 0                                                       
│       limit_tokens: 1.0                                                       
│       eval:                                                                   
│         l_max: null                                                           
│         batch_size: null                                                      
│                                                                               
├── dataset
│   └── _name_: wt2                                                             
│       data_dir: null                                                          
│       bpe: true                                                               
│       roll_seed: 42                                                           
│       test_split: true                                                        
│                                                                               
├── optimizer
│   └── _name_: adamw                                                           
│       lr: 0.0003                                                              
│       weight_decay: 0.1                                                       
│       betas:                                                                  
│       - 0.9                                                                   
│       - 0.999                                                                 
│                                                                               
├── scheduler
│   └── _name_: cosine_warmup                                                   
│       num_warmup_steps: 30064                                                 
│       num_training_steps: 300640                                              
│                                                                               
├── task
│   └── _name_: adaptivelm                                                      
│       init_scale: 0.5                                                         
│       bias_scale: 1.0                                                         
│       div_val: 1                                                              
│       cutoffs:                                                                
│       - 9997                                                                  
│       - 19997                                                                 
│       - 29997                                                                 
│       tie_weights: true                                                       
│       tie_projs:                                                              
│       - true                                                                  
│       - true                                                                  
│       - true                                                                  
│       dropemb: 0.25                                                           
│       dropsoft: 0.25                                                          
│       loss: null                                                              
│       metrics:                                                                
│       - ppl                                                                   
│                                                                               
├── encoder
│   └── None                                                                    
├── decoder
│   └── sequence                                                                
├── model
│   └── layer:                                                                  
│         cell:                                                                 
│           _name_: mirnn                                                       
│           hidden_activation: identity                                         
│           orthogonal: false                                                   
│           d_input: 384                                                        
│           lr: 7.5e-05                                                         
│         _name_: mirnn                                                         
│         return_output: true                                                   
│       _name_: model                                                           
│       prenorm: false                                                          
│       transposed: false                                                       
│       n_layers: 1                                                             
│       d_model: 384                                                            
│       bidirectional: false                                                    
│       residual: R                                                             
│       pool: null                                                              
│       norm: batch                                                             
│       dropout: 0.25                                                           
│       tie_dropout: false                                                      
│       track_norms: false                                                      
│       encoder: null                                                           
│       decoder: null                                                           
│                                                                               
└── callbacks
    └── learning_rate_monitor:                                                  
          logging_interval: step                                                
        timer:                                                                  
          step: true                                                            
          inter_step: false                                                     
          epoch: true                                                           
          val: true                                                             
        params:                                                                 
          total: true                                                           
          trainable: true                                                       
          fixed: true                                                           
        model_checkpoint:                                                       
          monitor: val/loss                                                     
          mode: min                                                             
          save_top_k: 1                                                         
          save_last: true                                                       
          dirpath: checkpoints/                                                 
          filename: val/loss                                                    
          auto_insert_metric_name: false                                        
          verbose: true                                                         
        rich_model_summary:                                                     
          max_depth: 1                                                          
        rich_progress_bar:                                                      
          refresh_rate: 1                                                       
          leave: true                                                           
                                                                                
[rank: 0] Global seed set to 1111
wandb: Currently logged in as: yuqinzhou. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in ./wandb/run-20230727_112718-bm14o686
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mirnn-lin-wt2
wandb: ⭐️ View project at https://wandb.ai/yuqinzhou/TNLM
wandb: 🚀 View run at https://wandb.ai/yuqinzhou/TNLM/runs/bm14o686
[2023-07-27 11:27:24,188][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.LearningRateMonitor>
[2023-07-27 11:27:24,189][__main__][INFO] - Instantiating callback <src.callbacks.timer.Timer>
[2023-07-27 11:27:24,193][__main__][INFO] - Instantiating callback <src.callbacks.params.ParamsLog>
[2023-07-27 11:27:24,195][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>
[2023-07-27 11:27:24,201][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichModelSummary>
[2023-07-27 11:27:24,201][__main__][INFO] - Instantiating callback <pytorch_lightning.callbacks.RichProgressBar>
Using 16bit None Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..
`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
vocab = OpenAIVocab()
vocab_size: 50257
[2023-07-27 11:27:24,793][root][INFO] - Loading cached dataset...
Vocab size: 50264
BPE: True
NOTE: no dropout inside recurrent cell
SequenceLightningModule(
  (model): SequenceModel(
    (drop): Identity()
    (layers): ModuleList(
      (0): SequenceResidualBlock(
        (layer): RNN(
          (cell): MIRNNCell(
            (W_hx): Linear(in_features=384, out_features=384, bias=False)
            (activate): Identity()
            (W_hh): Linear(in_features=384, out_features=384, bias=False)
          )
        )
        (residual): Residual()
        (norm): Normalization(
          (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (drop): Dropout(p=0.25, inplace=False)
        (output_linear): Sequential(
          (0): Conv1d(384, 768, kernel_size=(1,), stride=(1,))
          (1): GLU(dim=-2)
        )
        (activation): GELU(approximate=none)
      )
    )
    (norm): Identity()
  )
  (encoder): AdaptiveEmbedding(
    (0): AdaptiveEmbedding(
      (drop): Dropout(p=0.25, inplace=False)
      (emb_layers): ModuleList(
        (0): Embedding(50264, 384)
      )
      (emb_projs): ParameterList()
    )
  )
  (decoder): SequenceDecoder(
    (0): SequenceDecoder(
      (output_transform): Identity()
    )
  )
  (loss): ProjectedAdaptiveLogSoftmax(
    (out_layers_biases): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 50264])
    (shared_out_projs): ParameterList()
    (out_projs): OptionalParameterList()
    (drop): Dropout(p=0.25, inplace=False)
  )
  (loss_val): ProjectedAdaptiveLogSoftmax(
    (out_layers_biases): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 50264])
    (shared_out_projs): ParameterList()
    (out_projs): OptionalParameterList()
    (drop): Dropout(p=0.25, inplace=False)
  )
)
vocab = OpenAIVocab()
vocab_size: 50257
[2023-07-27 11:27:26,390][root][INFO] - Loading cached dataset...
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Vocab size: 50264
BPE: True
Hyperparameter groups [{'lr': 7.5e-05, 'weight_decay': 0.0}]
[2023-07-27 11:27:29,097][__main__][INFO] - Optimizer group 0 | 8 tensors | lr 0.0003 | weight_decay 0.1
[2023-07-27 11:27:29,097][__main__][INFO] - Optimizer group 1 | 2 tensors | lr 7.5e-05 | weight_decay 0.0
┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃   ┃ Name    ┃ Type                        ┃ Params ┃
┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0 │ model   │ SequenceModel               │  591 K │
│ 1 │ encoder │ AdaptiveEmbedding           │ 19.3 M │
│ 2 │ decoder │ SequenceDecoder             │      0 │
│ 3 │ loss    │ ProjectedAdaptiveLogSoftmax │ 51.4 K │
└───┴─────────┴─────────────────────────────┴────────┘
Trainable params: 19.9 M                                                        
Non-trainable params: 0                                                         
Total params: 19.9 M                                                            
Total estimated model params size (MB): 39                                      
SLURM auto-requeueing enabled. Setting signal handlers.
Epoch 0, global step 1531: 'val/loss' reached 9.99154 (best 9.99154), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
eval loader: {'l_max': 32, 'batch_size': 50, 'batch_first': True, 'pad_last': False, 'n_context': 1, 'n_epoch_double': 0, 'limit_tokens': 1.0}
eval loader: {'l_max': 32, 'batch_size': 50, 'batch_first': True, 'pad_last': False, 'n_context': 1, 'n_epoch_double': 0, 'limit_tokens': 1.0}
Epoch 0/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:54 •       39.22it/s loss: 10.1      
                                      0:00:00                   v_num: o686     
                                                                val/ppl:        
                                                                21915.67        
                                                                val/loss: 9.992 
                                                                test/ppl:       
                                                                21054.992       
                                                                test/loss: 9.951
                                                                train/ppl:      
                                                                32912.18        
                                                                train/loss:     
                                                                10.393          
Epoch 1, global step 3062: 'val/loss' reached 7.98725 (best 7.98725), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 1/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:55 •       37.76it/s loss: 7.85      
                                      0:00:00                   v_num: o686     
                                                                val/ppl:        
                                                                2961.666        
                                                                val/loss: 7.987 
                                                                test/ppl:       
                                                                2731.167        
                                                                test/loss: 7.905
                                                                train/ppl:      
                                                                12734.276       
                                                                train/loss:     
                                                                9.252           
Epoch 2, global step 4593: 'val/loss' reached 6.78497 (best 6.78497), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 2/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:55 •       38.00it/s loss: 6.83      
                                      0:00:00                   v_num: o686     
                                                                val/ppl: 888.49 
                                                                val/loss: 6.785 
                                                                test/ppl:       
                                                                815.103         
                                                                test/loss: 6.697
                                                                train/ppl:      
                                                                1405.281        
                                                                train/loss:     
                                                                7.206           
Epoch 3, global step 6124: 'val/loss' reached 6.53228 (best 6.53228), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 3/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:56 •       37.38it/s loss: 6.7 v_num:
                                      0:00:00                   o686 val/ppl:   
                                                                690.287         
                                                                val/loss: 6.532 
                                                                test/ppl:       
                                                                630.971         
                                                                test/loss: 6.441
                                                                train/ppl:      
                                                                901.434         
                                                                train/loss:     
                                                                6.796           
Epoch 4, global step 7655: 'val/loss' reached 6.49154 (best 6.49154), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 4/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:56 •       37.24it/s loss: 6.65      
                                      0:00:00                   v_num: o686     
                                                                val/ppl: 662.625
                                                                val/loss: 6.492 
                                                                test/ppl:       
                                                                609.183         
                                                                test/loss: 6.407
                                                                train/ppl:      
                                                                779.915         
                                                                train/loss:     
                                                                6.651           
Epoch 5, global step 9186: 'val/loss' reached 6.48343 (best 6.48343), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 5/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.66it/s loss: 6.57      
                                      0:00:00                   v_num: o686     
                                                                val/ppl: 657.121
                                                                val/loss: 6.483 
                                                                test/ppl:       
                                                                606.511         
                                                                test/loss: 6.402
                                                                train/ppl:      
                                                                704.504         
                                                                train/loss: 6.55
Epoch 6, global step 10717: 'val/loss' reached 6.45407 (best 6.45407), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 6/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:56 •       36.74it/s loss: 6.49      
                                      0:00:00                   v_num: o686     
                                                                val/ppl: 638.289
                                                                val/loss: 6.454 
                                                                test/ppl:       
                                                                589.731         
                                                                test/loss: 6.374
                                                                train/ppl:      
                                                                647.613         
                                                                train/loss:     
                                                                6.465           
Epoch 7, global step 12248: 'val/loss' reached 6.44827 (best 6.44827), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 7/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.39it/s loss: 6.29      
                                      0:00:00                   v_num: o686     
                                                                val/ppl: 634.437
                                                                val/loss: 6.448 
                                                                test/ppl:       
                                                                586.445         
                                                                test/loss: 6.368
                                                                train/ppl:      
                                                                595.57          
                                                                train/loss:     
                                                                6.381           
Epoch 8, global step 13779: 'val/loss' was not in top 1
Epoch 8/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.61it/s loss: 6.23      
                                      0:00:00                   v_num: o686     
                                                                val/ppl: 637.552
                                                                val/loss: 6.453 
                                                                test/ppl:       
                                                                589.205         
                                                                test/loss: 6.373
                                                                train/ppl:      
                                                                550.738         
                                                                train/loss:     
                                                                6.302           
Epoch 9, global step 15310: 'val/loss' was not in top 1
Epoch 9/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.39it/s loss: 6.16      
                                      0:00:00                   v_num: o686     
                                                                val/ppl: 643.138
                                                                val/loss: 6.461 
                                                                test/ppl:       
                                                                592.668         
                                                                test/loss: 6.379
                                                                train/ppl:      
                                                                509.727         
                                                                train/loss:     
                                                                6.226           
Epoch 10, global step 16841: 'val/loss' was not in top 1
Epoch 10/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.12it/s loss: 6.17     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 645.915        
                                                                 val/loss: 6.465
                                                                 test/ppl:      
                                                                 594.841        
                                                                 test/loss:     
                                                                 6.382          
                                                                 train/ppl:     
                                                                 474.253        
                                                                 train/loss:    
                                                                 6.154          
Epoch 11, global step 18372: 'val/loss' reached 6.44432 (best 6.44432), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 11/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.67it/s loss: 6.03     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 633.362        
                                                                 val/loss: 6.444
                                                                 test/ppl:      
                                                                 579.85         
                                                                 test/loss:     
                                                                 6.356          
                                                                 train/ppl:     
                                                                 443.451        
                                                                 train/loss:    
                                                                 6.086          
Epoch 12, global step 19903: 'val/loss' reached 6.38136 (best 6.38136), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 12/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.75it/s loss: 6.01     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 594.319        
                                                                 val/loss: 6.381
                                                                 test/ppl:      
                                                                 544.84         
                                                                 test/loss:     
                                                                 6.293          
                                                                 train/ppl:     
                                                                 415.19         
                                                                 train/loss:    
                                                                 6.021          
Epoch 13, global step 21434: 'val/loss' reached 6.24617 (best 6.24617), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 13/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.74it/s loss: 5.93     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl: 519.34
                                                                 val/loss: 6.246
                                                                 test/ppl:      
                                                                 474.449        
                                                                 test/loss:     
                                                                 6.155          
                                                                 train/ppl:     
                                                                 390.197        
                                                                 train/loss:    
                                                                 5.959          
Epoch 14, global step 22965: 'val/loss' reached 6.14432 (best 6.14432), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 14/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:57 •       36.55it/s loss: 5.82     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 469.008        
                                                                 val/loss: 6.144
                                                                 test/ppl:      
                                                                 425.267        
                                                                 test/loss:     
                                                                 6.046          
                                                                 train/ppl:     
                                                                 368.601        
                                                                 train/loss:    
                                                                 5.902          
Epoch 15, global step 24496: 'val/loss' reached 5.99765 (best 5.99765), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 15/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:59 •       35.54it/s loss: 5.86     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 405.142        
                                                                 val/loss: 5.998
                                                                 test/ppl:      
                                                                 369.392        
                                                                 test/loss:     
                                                                 5.904          
                                                                 train/ppl:     
                                                                 349.54         
                                                                 train/loss:    
                                                                 5.849          
Epoch 16, global step 26027: 'val/loss' reached 5.95824 (best 5.95824), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 16/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:59 •       35.48it/s loss: 5.77     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 389.272        
                                                                 val/loss: 5.958
                                                                 test/ppl:      
                                                                 351.986        
                                                                 test/loss:     
                                                                 5.857          
                                                                 train/ppl:     
                                                                 333.008        
                                                                 train/loss:    
                                                                 5.801          
Epoch 17, global step 27558: 'val/loss' reached 5.89840 (best 5.89840), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 17/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:58 •       36.50it/s loss: 5.8      
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 366.945        
                                                                 val/loss: 5.898
                                                                 test/ppl:      
                                                                 327.943        
                                                                 test/loss:     
                                                                 5.785          
                                                                 train/ppl:     
                                                                 319.532        
                                                                 train/loss:    
                                                                 5.76           
Epoch 18, global step 29089: 'val/loss' reached 5.89494 (best 5.89494), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 18/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:58 •       35.94it/s loss: 5.61     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 365.411        
                                                                 val/loss: 5.895
                                                                 test/ppl:      
                                                                 328.684        
                                                                 test/loss:     
                                                                 5.787          
                                                                 train/ppl:     
                                                                 308.175        
                                                                 train/loss:    
                                                                 5.723          
Epoch 19, global step 30620: 'val/loss' reached 5.84546 (best 5.84546), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 19/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:58 •       36.15it/s loss: 5.65     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 348.031        
                                                                 val/loss: 5.845
                                                                 test/ppl:      
                                                                 311.199        
                                                                 test/loss:     
                                                                 5.732          
                                                                 train/ppl:     
                                                                 298.62         
                                                                 train/loss:    
                                                                 5.692          
Epoch 20, global step 32151: 'val/loss' reached 5.75519 (best 5.75519), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 20/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:58 •       36.13it/s loss: 5.64     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 318.104        
                                                                 val/loss: 5.755
                                                                 test/ppl:      
                                                                 284.013        
                                                                 test/loss:     
                                                                 5.641          
                                                                 train/ppl:     
                                                                 290.373        
                                                                 train/loss:    
                                                                 5.664          
Epoch 21, global step 33682: 'val/loss' was not in top 1
Epoch 21/199 ━━━━━━━━━━━━━━━ 1878/1878 0:00:58 •       35.61it/s loss: 5.69     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 320.075        
                                                                 val/loss: 5.762
                                                                 test/ppl:      
                                                                 289.189        
                                                                 test/loss:     
                                                                 5.659          
                                                                 train/ppl:     
                                                                 282.62         
                                                                 train/loss:    
                                                                 5.636          
Epoch 22, global step 35213: 'val/loss' reached 5.70710 (best 5.70710), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 22/199 ━━━━━━━━━━━━━━━ 1878/1878 0:01:00 •       34.80it/s loss: 5.63     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 303.229        
                                                                 val/loss: 5.707
                                                                 test/ppl:      
                                                                 270.48         
                                                                 test/loss:     
                                                                 5.592          
                                                                 train/ppl:     
                                                                 275.351        
                                                                 train/loss:    
                                                                 5.611          
Epoch 23, global step 36744: 'val/loss' was not in top 1
Epoch 23/199 ━━━━━━━━━━━━━━━ 1878/1878 0:01:00 •       34.52it/s loss: 5.6      
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 304.742        
                                                                 val/loss: 5.713
                                                                 test/ppl:      
                                                                 271.592        
                                                                 test/loss:     
                                                                 5.596          
                                                                 train/ppl:     
                                                                 269.484        
                                                                 train/loss:    
                                                                 5.589          
Epoch 24, global step 38275: 'val/loss' reached 5.68364 (best 5.68364), saving model to '/home/qvk729/Master_thesis/outputs/2023-07-27/11-27-16-310906/checkpoints/val/loss.ckpt' as top 1
Epoch 24/199 ━━━━━━━━━━━━━━━ 1878/1878 0:01:00 •       34.51it/s loss: 5.55     
                                       0:00:00                   v_num: o686    
                                                                 val/ppl:       
                                                                 296.301        
                                                                 val/loss: 5.684
                                                                 test/ppl:      
                                                                 267.73         
                                                                 test/loss:     
                                                                 5.581          
                                                                 train/ppl:     
                                                                 263.542        
                                                                 train/loss:    
                                                                 5.567          
