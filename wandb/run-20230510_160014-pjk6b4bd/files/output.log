Epoch: 1 | Val acc: 21.060:   0%|          | 0/199 [00:00<?, ?it/s]
Batch Idx: (7/900) | Loss: 2.101 | Acc: 20.000% (80/400): : 8it [00:01,  4.01it/s]
==> Resuming from checkpoint...
==> Training...






Batch Idx: (54/900) | Loss: 2.097 | Acc: 21.782% (599/2750): : 55it [00:14,  3.76it/s]





Batch Idx: (92/900) | Loss: 2.094 | Acc: 21.161% (984/4650): : 93it [00:24,  3.97it/s]







Batch Idx: (146/900) | Loss: 2.097 | Acc: 20.503% (1507/7350): : 147it [00:38,  3.87it/s]







Batch Idx: (202/900) | Loss: 2.099 | Acc: 20.502% (2081/10150): : 203it [00:52,  3.96it/s]






Batch Idx: (249/900) | Loss: 2.099 | Acc: 20.624% (2578/12500): : 250it [01:04,  3.99it/s]






Batch Idx: (295/900) | Loss: 2.095 | Acc: 20.703% (3064/14800): : 296it [01:16,  3.83it/s]







Batch Idx: (350/900) | Loss: 2.093 | Acc: 20.815% (3653/17550): : 351it [01:30,  3.80it/s]






Batch Idx: (397/900) | Loss: 2.093 | Acc: 20.739% (4127/19900): : 398it [01:42,  3.67it/s]






Batch Idx: (444/900) | Loss: 2.093 | Acc: 20.692% (4604/22250): : 445it [01:54,  3.64it/s]







Batch Idx: (496/900) | Loss: 2.092 | Acc: 20.704% (5145/24850): : 497it [02:08,  3.93it/s]






Batch Idx: (543/900) | Loss: 2.091 | Acc: 20.717% (5635/27200): : 544it [02:20,  3.89it/s]







Batch Idx: (597/900) | Loss: 2.091 | Acc: 20.639% (6171/29900): : 598it [02:34,  3.91it/s]







Batch Idx: (651/900) | Loss: 2.092 | Acc: 20.629% (6725/32600): : 652it [02:48,  3.78it/s]






Batch Idx: (696/900) | Loss: 2.090 | Acc: 20.735% (7226/34850): : 697it [03:00,  3.81it/s]







Batch Idx: (749/900) | Loss: 2.091 | Acc: 20.712% (7767/37500): : 750it [03:14,  3.86it/s]






Batch Idx: (794/900) | Loss: 2.090 | Acc: 20.702% (8229/39750): : 795it [03:26,  3.76it/s]







Batch Idx: (849/900) | Loss: 2.089 | Acc: 20.781% (8832/42500): : 850it [03:40,  3.85it/s]






Batch Idx: (894/900) | Loss: 2.089 | Acc: 20.796% (9306/44750): : 895it [03:52,  3.78it/s]
Batch Idx: (899/900) | Loss: 2.089 | Acc: 20.820% (9369/45000): : 900it [03:53,  3.72it/s]



Batch Idx: (79/100) | Loss: 2.079 | Acc: 21.875% (875/4000): : 80it [00:06, 12.07it/s]
Epoch 1 learning rate: [0.00035714285714285714]
==> Training...
Epoch: 2 | Val acc: 21.580:   1%|          | 1/199 [04:02<13:20:48, 242.67s/it]1.84it/s]






Batch Idx: (45/900) | Loss: 2.062 | Acc: 21.739% (500/2300): : 46it [00:12,  3.72it/s]







Batch Idx: (96/900) | Loss: 2.074 | Acc: 21.278% (1032/4850): : 97it [00:25,  3.91it/s]







Batch Idx: (149/900) | Loss: 2.067 | Acc: 21.467% (1610/7500): : 150it [00:40,  3.92it/s]






Batch Idx: (196/900) | Loss: 2.074 | Acc: 21.228% (2091/9850): : 197it [00:52,  3.63it/s]







Batch Idx: (250/900) | Loss: 2.071 | Acc: 21.458% (2693/12550): : 251it [01:06,  3.95it/s]






Batch Idx: (296/900) | Loss: 2.073 | Acc: 21.300% (3163/14850): : 297it [01:18,  3.92it/s]







Batch Idx: (348/900) | Loss: 2.077 | Acc: 21.387% (3732/17450): : 349it [01:32,  3.94it/s]






Batch Idx: (396/900) | Loss: 2.078 | Acc: 21.491% (4266/19850): : 397it [01:44,  3.90it/s]






Batch Idx: (444/900) | Loss: 2.076 | Acc: 21.560% (4797/22250): : 445it [01:56,  4.00it/s]







Batch Idx: (500/900) | Loss: 2.075 | Acc: 21.613% (5414/25050): : 501it [02:10,  3.98it/s]






Batch Idx: (548/900) | Loss: 2.073 | Acc: 21.683% (5952/27450): : 549it [02:22,  4.01it/s]






Batch Idx: (594/900) | Loss: 2.073 | Acc: 21.761% (6474/29750): : 595it [02:34,  3.91it/s]







Batch Idx: (649/900) | Loss: 2.074 | Acc: 21.782% (7079/32500): : 650it [02:48,  4.00it/s]






Batch Idx: (696/900) | Loss: 2.073 | Acc: 21.845% (7613/34850): : 697it [03:00,  3.86it/s]







Batch Idx: (750/900) | Loss: 2.073 | Acc: 21.763% (8172/37550): : 751it [03:14,  3.91it/s]






Batch Idx: (798/900) | Loss: 2.073 | Acc: 21.760% (8693/39950): : 799it [03:26,  3.97it/s]






Batch Idx: (844/900) | Loss: 2.073 | Acc: 21.789% (9206/42250): : 845it [03:38,  3.95it/s]






Batch Idx: (892/900) | Loss: 2.071 | Acc: 21.866% (9763/44650): : 893it [03:50,  3.98it/s]
Batch Idx: (899/900) | Loss: 2.071 | Acc: 21.909% (9859/45000): : 900it [03:52,  4.01it/s]



Batch Idx: (80/100) | Loss: 2.061 | Acc: 21.852% (885/4050): : 80it [00:06, 12.47it/s]
Epoch 2 learning rate: [0.0004761904761904762]
==> Training...
Epoch: 3 | Val acc: 21.640:   1%|          | 2/199 [08:02<13:11:51, 241.17s/it]2.75it/s]






Batch Idx: (46/900) | Loss: 2.020 | Acc: 24.170% (568/2350): : 47it [00:12,  3.64it/s]






Batch Idx: (94/900) | Loss: 2.039 | Acc: 23.011% (1093/4750): : 95it [00:24,  3.89it/s]







Batch Idx: (148/900) | Loss: 2.052 | Acc: 22.846% (1702/7450): : 149it [00:38,  3.99it/s]






Batch Idx: (194/900) | Loss: 2.056 | Acc: 22.872% (2230/9750): : 195it [00:50,  3.85it/s]




Epoch: 3 | Val acc: 21.640:   1%|          | 2/199 [09:01<14:48:28, 270.60s/it]  3.40it/s]
/Users/zhouyuqin/Desktop/Thesis/experiments/src/utils/optim/schedulers.py:21: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
./checkpoint/checkpoint_zdbv2atb.pth