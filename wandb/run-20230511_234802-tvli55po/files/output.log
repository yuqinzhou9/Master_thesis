Epoch: 0:   0%|          | 0/200 [00:00<?, ?it/s]
Batch Idx: (5/900) | Loss: 2.351 | Acc: 9.000% (27/300): : 6it [00:01,  3.79it/s]
==> Building model / ...
Optimizer group 0 | 12 tensors | lr 0.0004761904761904762 | weight_decay 0.05
Optimizer group 1 | 4 tensors | lr 0.00011904761904761905 | weight_decay 0.0
==> Training...





Batch Idx: (45/900) | Loss: 2.359 | Acc: 10.087% (232/2300): : 46it [00:11,  3.98it/s]







Batch Idx: (99/900) | Loss: 2.333 | Acc: 11.000% (550/5000): : 100it [00:25,  3.78it/s]






Batch Idx: (145/900) | Loss: 2.323 | Acc: 11.274% (823/7300): : 146it [00:38,  3.97it/s]







Batch Idx: (199/900) | Loss: 2.313 | Acc: 11.530% (1153/10000): : 200it [00:52,  3.67it/s]






Batch Idx: (244/900) | Loss: 2.304 | Acc: 11.829% (1449/12250): : 245it [01:04,  3.62it/s]







Batch Idx: (297/900) | Loss: 2.293 | Acc: 12.282% (1830/14900): : 298it [01:17,  3.98it/s]






Batch Idx: (345/900) | Loss: 2.286 | Acc: 12.803% (2215/17300): : 346it [01:30,  3.93it/s]






Batch Idx: (393/900) | Loss: 2.279 | Acc: 13.310% (2622/19700): : 394it [01:42,  3.99it/s]







Batch Idx: (449/900) | Loss: 2.271 | Acc: 13.791% (3103/22500): : 450it [01:56,  3.97it/s]






Batch Idx: (494/900) | Loss: 2.264 | Acc: 14.141% (3500/24750): : 495it [02:07,  3.91it/s]






Batch Idx: (542/900) | Loss: 2.257 | Acc: 14.431% (3918/27150): : 543it [02:19,  3.99it/s]







Batch Idx: (598/900) | Loss: 2.249 | Acc: 14.888% (4459/29950): : 599it [02:34,  3.92it/s]






Batch Idx: (645/900) | Loss: 2.242 | Acc: 15.341% (4955/32300): : 646it [02:46,  3.89it/s]







Batch Idx: (697/900) | Loss: 2.234 | Acc: 15.613% (5449/34900): : 698it [03:00,  3.92it/s]







Batch Idx: (750/900) | Loss: 2.228 | Acc: 15.832% (5945/37550): : 751it [03:14,  3.91it/s]






Batch Idx: (794/900) | Loss: 2.223 | Acc: 16.013% (6365/39750): : 795it [03:26,  3.66it/s]






Batch Idx: (841/900) | Loss: 2.217 | Acc: 16.235% (6835/42100): : 842it [03:38,  3.98it/s]







Batch Idx: (894/900) | Loss: 2.211 | Acc: 16.485% (7377/44750): : 895it [03:52,  3.79it/s]
Batch Idx: (899/900) | Loss: 2.210 | Acc: 16.522% (7435/45000): : 900it [03:53,  3.90it/s]



Batch Idx: (79/100) | Loss: 2.107 | Acc: 22.075% (883/4000): : 80it [00:06, 11.76it/s]
==> Training...
Epoch: 1 | Val acc: 21.560:   0%|          | 1/200 [04:02<13:23:44, 242.33s/it]1.97it/s]






Batch Idx: (45/900) | Loss: 2.104 | Acc: 22.478% (517/2300): : 46it [00:12,  3.87it/s]






Batch Idx: (92/900) | Loss: 2.094 | Acc: 22.237% (1034/4650): : 93it [00:23,  3.97it/s]







Batch Idx: (148/900) | Loss: 2.091 | Acc: 21.960% (1636/7450): : 149it [00:38,  3.97it/s]






Batch Idx: (197/900) | Loss: 2.087 | Acc: 22.071% (2185/9900): : 198it [00:50,  4.03it/s]






Batch Idx: (246/900) | Loss: 2.081 | Acc: 22.138% (2734/12350): : 247it [01:02,  4.02it/s]






Batch Idx: (294/900) | Loss: 2.078 | Acc: 22.115% (3262/14750): : 295it [01:14,  4.01it/s]






Batch Idx: (341/900) | Loss: 2.076 | Acc: 22.094% (3778/17100): : 342it [01:26,  3.90it/s]







Batch Idx: (395/900) | Loss: 2.074 | Acc: 22.152% (4386/19800): : 396it [01:40,  3.73it/s]







Batch Idx: (449/900) | Loss: 2.074 | Acc: 22.031% (4957/22500): : 450it [01:54,  3.99it/s]






Batch Idx: (497/900) | Loss: 2.075 | Acc: 21.876% (5447/24900): : 498it [02:06,  3.97it/s]






Batch Idx: (545/900) | Loss: 2.076 | Acc: 21.810% (5954/27300): : 546it [02:18,  3.92it/s]







Batch Idx: (598/900) | Loss: 2.074 | Acc: 21.913% (6563/29950): : 599it [02:32,  3.97it/s]






Batch Idx: (646/900) | Loss: 2.074 | Acc: 21.802% (7053/32350): : 647it [02:44,  3.98it/s]






Batch Idx: (694/900) | Loss: 2.075 | Acc: 21.683% (7535/34750): : 695it [02:56,  3.95it/s]







Batch Idx: (750/900) | Loss: 2.073 | Acc: 21.758% (8170/37550): : 751it [03:10,  3.98it/s]






Batch Idx: (798/900) | Loss: 2.072 | Acc: 21.785% (8703/39950): : 799it [03:22,  3.95it/s]






Batch Idx: (843/900) | Loss: 2.072 | Acc: 21.784% (9193/42200): : 844it [03:34,  3.88it/s]






Batch Idx: (891/900) | Loss: 2.070 | Acc: 21.908% (9771/44600): : 892it [03:46,  3.95it/s]
Batch Idx: (899/900) | Loss: 2.070 | Acc: 21.904% (9857/45000): : 900it [03:48,  3.98it/s]



Batch Idx: (76/100) | Loss: 2.040 | Acc: 23.221% (894/3850): : 76it [00:06, 12.41it/s]
Epoch: 2 | Val acc: 22.720:   1%|          | 2/200 [07:59<13:08:49, 239.04s/it]2.21it/s]
0it [00:00, ?it/s]






Batch Idx: (47/900) | Loss: 2.043 | Acc: 24.208% (581/2400): : 48it [00:12,  3.98it/s]






Batch Idx: (94/900) | Loss: 2.046 | Acc: 23.747% (1128/4750): : 95it [00:24,  3.88it/s]







Batch Idx: (146/900) | Loss: 2.044 | Acc: 23.565% (1732/7350): : 147it [00:37,  3.93it/s]






Batch Idx: (194/900) | Loss: 2.039 | Acc: 23.313% (2273/9750): : 195it [00:49,  4.03it/s]







Batch Idx: (250/900) | Loss: 2.040 | Acc: 23.498% (2949/12550): : 251it [01:04,  4.02it/s]






Batch Idx: (297/900) | Loss: 2.039 | Acc: 23.443% (3493/14900): : 298it [01:15,  4.04it/s]






Batch Idx: (347/900) | Loss: 2.036 | Acc: 23.655% (4116/17400): : 348it [01:28,  3.99it/s]






Batch Idx: (393/900) | Loss: 2.034 | Acc: 23.756% (4680/19700): : 394it [01:40,  4.01it/s]







Batch Idx: (449/900) | Loss: 2.031 | Acc: 23.849% (5366/22500): : 450it [01:54,  3.96it/s]






Batch Idx: (497/900) | Loss: 2.028 | Acc: 23.880% (5946/24900): : 498it [02:06,  4.04it/s]






Batch Idx: (546/900) | Loss: 2.030 | Acc: 23.810% (6512/27350): : 547it [02:18,  4.02it/s]







Batch Idx: (599/900) | Loss: 2.029 | Acc: 23.743% (7123/30000): : 600it [02:32,  3.75it/s]






Batch Idx: (644/900) | Loss: 2.028 | Acc: 23.749% (7659/32250): : 645it [02:44,  3.93it/s]







Batch Idx: (700/900) | Loss: 2.024 | Acc: 23.857% (8362/35050): : 701it [02:58,  3.91it/s]






Batch Idx: (748/900) | Loss: 2.023 | Acc: 23.904% (8952/37450): : 749it [03:10,  4.03it/s]






Batch Idx: (796/900) | Loss: 2.023 | Acc: 23.950% (9544/39850): : 797it [03:22,  3.96it/s]






Batch Idx: (844/900) | Loss: 2.021 | Acc: 24.064% (10167/42250): : 845it [03:34,  3.97it/s]







Batch Idx: (898/900) | Loss: 2.020 | Acc: 24.116% (10840/44950): : 899it [03:48,  3.98it/s]
Batch Idx: (899/900) | Loss: 2.020 | Acc: 24.107% (10848/45000): : 900it [03:48,  3.96it/s]



Batch Idx: (97/100) | Loss: 1.997 | Acc: 25.735% (1261/4900): : 98it [00:07, 12.32it/s]
==> Training...
Epoch: 3 | Val acc: 25.640:   2%|▏         | 3/200 [11:55<13:01:21, 237.98s/it]2.38it/s]





Batch Idx: (47/900) | Loss: 1.997 | Acc: 25.167% (604/2400): : 48it [00:11,  4.01it/s]






Batch Idx: (95/900) | Loss: 1.997 | Acc: 25.104% (1205/4800): : 96it [00:24,  3.97it/s]







Batch Idx: (149/900) | Loss: 1.994 | Acc: 25.240% (1893/7500): : 150it [00:38,  3.71it/s]






Batch Idx: (194/900) | Loss: 1.999 | Acc: 25.159% (2453/9750): : 195it [00:49,  3.91it/s]







Batch Idx: (243/900) | Loss: 1.996 | Acc: 25.410% (3100/12200): : 244it [01:03,  3.97it/s]







Batch Idx: (296/900) | Loss: 1.995 | Acc: 25.468% (3782/14850): : 297it [01:17,  3.71it/s]







Batch Idx: (350/900) | Loss: 1.994 | Acc: 25.481% (4472/17550): : 351it [01:32,  3.81it/s]






Batch Idx: (397/900) | Loss: 1.995 | Acc: 25.417% (5058/19900): : 398it [01:44,  3.99it/s]






Batch Idx: (443/900) | Loss: 1.997 | Acc: 25.342% (5626/22200): : 444it [01:56,  3.96it/s]







Batch Idx: (499/900) | Loss: 1.996 | Acc: 25.292% (6323/25000): : 500it [02:10,  3.99it/s]






Batch Idx: (548/900) | Loss: 1.995 | Acc: 25.355% (6960/27450): : 549it [02:22,  3.97it/s]






Batch Idx: (594/900) | Loss: 1.995 | Acc: 25.311% (7530/29750): : 595it [02:34,  3.93it/s]







Batch Idx: (649/900) | Loss: 1.996 | Acc: 25.252% (8207/32500): : 650it [02:48,  4.03it/s]






Batch Idx: (695/900) | Loss: 1.997 | Acc: 25.184% (8764/34800): : 696it [03:00,  3.48it/s]







Batch Idx: (749/900) | Loss: 1.997 | Acc: 25.171% (9439/37500): : 750it [03:14,  3.84it/s]






Batch Idx: (797/900) | Loss: 1.998 | Acc: 25.128% (10026/39900): : 798it [03:26,  3.97it/s]






Batch Idx: (842/900) | Loss: 1.998 | Acc: 25.122% (10589/42150): : 843it [03:38,  3.95it/s]







Batch Idx: (898/900) | Loss: 1.997 | Acc: 25.128% (11295/44950): : 899it [03:52,  3.96it/s]
Batch Idx: (899/900) | Loss: 1.997 | Acc: 25.122% (11305/45000): : 900it [03:52,  3.97it/s]



Batch Idx: (94/100) | Loss: 1.989 | Acc: 25.979% (1234/4750): : 94it [00:07, 12.42it/s]
==> Training...
Epoch: 4 | Val acc: 26.000:   2%|▏         | 4/200 [15:56<13:01:11, 239.14s/it]1.44it/s]





Batch Idx: (45/900) | Loss: 1.982 | Acc: 25.696% (591/2300): : 46it [00:11,  3.98it/s]







Batch Idx: (101/900) | Loss: 1.995 | Acc: 25.353% (1293/5100): : 102it [00:25,  3.96it/s]






Batch Idx: (148/900) | Loss: 1.990 | Acc: 25.477% (1898/7450): : 149it [00:37,  3.91it/s]






Batch Idx: (194/900) | Loss: 1.997 | Acc: 25.221% (2459/9750): : 195it [00:49,  3.98it/s]







Batch Idx: (249/900) | Loss: 2.000 | Acc: 25.144% (3143/12500): : 250it [01:03,  3.95it/s]






Batch Idx: (295/900) | Loss: 2.001 | Acc: 25.081% (3712/14800): : 296it [01:15,  3.83it/s]







Batch Idx: (348/900) | Loss: 2.000 | Acc: 25.232% (4403/17450): : 349it [01:29,  3.58it/s]






Batch Idx: (396/900) | Loss: 1.996 | Acc: 25.466% (5055/19850): : 397it [01:42,  3.98it/s]







Batch Idx: (449/900) | Loss: 1.994 | Acc: 25.533% (5745/22500): : 450it [01:55,  3.99it/s]






Batch Idx: (495/900) | Loss: 1.995 | Acc: 25.456% (6313/24800): : 496it [02:07,  3.76it/s]







Batch Idx: (550/900) | Loss: 1.997 | Acc: 25.347% (6983/27550): : 551it [02:21,  3.88it/s]






Batch Idx: (595/900) | Loss: 1.996 | Acc: 25.379% (7563/29800): : 596it [02:33,  3.75it/s]






Batch Idx: (643/900) | Loss: 1.996 | Acc: 25.404% (8180/32200): : 644it [02:46,  3.99it/s]







Batch Idx: (697/900) | Loss: 1.995 | Acc: 25.390% (8861/34900): : 698it [02:59,  3.81it/s]






Batch Idx: (746/900) | Loss: 1.996 | Acc: 25.285% (9444/37350): : 747it [03:11,  4.04it/s]






Batch Idx: (795/900) | Loss: 1.994 | Acc: 25.302% (10070/39800): : 796it [03:24,  4.06it/s]






Batch Idx: (843/900) | Loss: 1.994 | Acc: 25.325% (10687/42200): : 844it [03:36,  4.00it/s]






Batch Idx: (899/900) | Loss: 1.993 | Acc: 25.391% (11426/45000): : 900it [03:50,  4.06it/s]
Batch Idx: (3/100) | Loss: 2.029 | Acc: 25.500% (51/200): : 4it [00:00, 12.77it/s]



Batch Idx: (74/100) | Loss: 1.988 | Acc: 25.787% (967/3750): : 74it [00:05, 12.69it/s]
Epoch: 5 | Val acc: 25.440:   2%|▎         | 5/200 [19:54<12:55:53, 238.74s/it]2.72it/s]
0it [00:00, ?it/s]






Batch Idx: (45/900) | Loss: 1.949 | Acc: 26.522% (610/2300): : 46it [00:12,  3.75it/s]







Batch Idx: (99/900) | Loss: 1.975 | Acc: 26.040% (1302/5000): : 100it [00:26,  3.81it/s]






Batch Idx: (147/900) | Loss: 1.983 | Acc: 25.459% (1884/7400): : 148it [00:38,  4.01it/s]






Batch Idx: (196/900) | Loss: 1.980 | Acc: 25.584% (2520/9850): : 197it [00:50,  4.02it/s]






Batch Idx: (242/900) | Loss: 1.983 | Acc: 25.630% (3114/12150): : 243it [01:02,  3.97it/s]







Batch Idx: (299/900) | Loss: 1.985 | Acc: 25.647% (3847/15000): : 300it [01:16,  3.91it/s]






Batch Idx: (347/900) | Loss: 1.988 | Acc: 25.695% (4471/17400): : 348it [01:28,  3.92it/s]






Batch Idx: (395/900) | Loss: 1.996 | Acc: 25.586% (5066/19800): : 396it [01:40,  4.00it/s]







Batch Idx: (451/900) | Loss: 1.992 | Acc: 25.646% (5796/22600): : 452it [01:54,  3.86it/s]






Batch Idx: (495/900) | Loss: 1.993 | Acc: 25.649% (6361/24800): : 496it [02:06,  3.73it/s]







Batch Idx: (550/900) | Loss: 1.994 | Acc: 25.626% (7060/27550): : 551it [02:20,  3.99it/s]






Batch Idx: (596/900) | Loss: 1.994 | Acc: 25.531% (7621/29850): : 597it [02:32,  3.68it/s]







Batch Idx: (650/900) | Loss: 1.994 | Acc: 25.601% (8333/32550): : 651it [02:46,  3.70it/s]






Batch Idx: (694/900) | Loss: 1.994 | Acc: 25.568% (8885/34750): : 695it [02:58,  3.77it/s]

Epoch: 5 | Val acc: 25.440:   2%|▎         | 5/200 [22:54<14:53:31, 274.93s/it]  3.56it/s]
Namespace(batch_size=50, cell='rnn', d_hidden=196, d_model=128, dataset='cifar10', dropout=0.1, epochs=200, grayscale=False, lr=0.01, lr_factor=0.25, n_layers=2, norm='BN', num_workers=0, prenorm=True, resume=False, weight_decay=0.05)
{'weight_decay': 0.0, 'lr': 0.0025}
{'weight_decay': 0.0, 'lr': 0.0025}
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
torch.Size([50, 1024, 3]) tensor([1, 7, 9, 6, 3, 8, 9, 1, 5, 7, 4, 7, 6, 1, 9, 2, 8, 8, 8, 9, 9, 3, 5, 7,
        7, 9, 9, 3, 9, 3, 6, 4, 2, 7, 1, 5, 0, 8, 5, 3, 5, 9, 3, 5, 3, 0, 3, 2,
        4, 5])
RNNbased(
  (encoder): Linear(in_features=3, out_features=128, bias=True)
  (layers): ModuleList(
    (0): RNN(
      (cell): RNNCell(
        (W_hx): Linear(in_features=128, out_features=196, bias=False)
        (activate): Tanh()
        (W_hh): Linear(in_features=196, out_features=196, bias=False)
      )
    )
    (1): RNN(
      (cell): RNNCell(
        (W_hx): Linear(in_features=128, out_features=196, bias=False)
        (activate): Tanh()
        (W_hh): Linear(in_features=196, out_features=196, bias=False)
      )
    )
  )
  (norms): ModuleList(
    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (dropouts): ModuleList(
    (0): Dropout1d(p=0.1, inplace=False)
    (1): Dropout1d(p=0.1, inplace=False)
  )
  (FFNs): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=196, out_features=256, bias=True)
      (1): GLU(dim=-1)
    )
    (1): Sequential(
      (0): Linear(in_features=196, out_features=256, bias=True)
      (1): GLU(dim=-1)
    )
  )
  (decoder): Linear(in_features=128, out_features=10, bias=True)
)
Optimizer group 0 | 12 tensors | lr 0.0004761904761904762 | weight_decay 0.05
Optimizer group 1 | 4 tensors | lr 0.00011904761904761905 | weight_decay 0.0
